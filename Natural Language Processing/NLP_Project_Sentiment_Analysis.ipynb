{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Prep\n",
    "\n",
    "Load, clean, and preprocess the data as you find necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  600 non-null    object\n",
      " 1   Polarity  600 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0  A good commentary of today's love and undoubte...         1\n",
      "1  For people who are first timers in film making...         1\n",
      "2  It was very popular when I was in the cinema, ...         1\n",
      "3  It's a feel-good film and that's how I felt wh...         1\n",
      "4  It has northern humour and positive about the ...         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohammadananjaved/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohammadananjaved/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mohammadananjaved/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from collections import Counter\n",
    "\n",
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_test.info())\n",
    "print(df_test.head())\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing functions to count the number of special characters. The idea is that negative sentiment reviews will have a lot of exclamation points, question marks & caps locks. This step is performed prior to preprocessing the data to remove punctuations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_specials(sentence):\n",
    "\n",
    "    num_question_marks = 0\n",
    "    num_exclamation_points = 0\n",
    "    num_caps_lock = 0\n",
    "\n",
    "    for char in sentence:\n",
    "        if char == '?':\n",
    "            num_question_marks += 1\n",
    "        elif char == '!':\n",
    "            num_exclamation_points += 1\n",
    "        elif char.isupper():\n",
    "            num_caps_lock += 1\n",
    "\n",
    "    return num_question_marks + num_exclamation_points + num_caps_lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_special_characters(data):\n",
    "    data['special_character_count'] = [count_specials(sentence) for sentence in data['Sentence']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stop Words with a Negative Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words which are classified as stop words are required to present the negative sentiment, such as, no, not, shouldn't, etc. Those words are deliberately removed from the list of stop words. This would ensure these words are present post stop word removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove = ['no', 'not', \"don't\", \"didn't\", \"didn'\", \"haven'\", \"haven't\", \"shouldn'\", \"shouldn't\", \"wasn'\",\n",
    "                  \"wasn't\", \"weren'\", \"weren't\"]\n",
    "\n",
    "stop_words = [word for word in stop_words if word not in words_to_remove]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenizing the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Removing punctuations from the text\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    #Removing numbers from the text\n",
    "    tokens = [token for token in tokens if not token.isnumeric()]\n",
    "    \n",
    "    # Removing stopwords from the text and converting it to lowercase\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "        \n",
    "    # Stemming the text\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "        \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_df(data):\n",
    "    data['processed_text'] = data['Sentence'].apply(preprocess_text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are generated to get the total count of words in a sentence, the count of frequently occurring positive words, the count of frequently occurring negative words and the count of characters in sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus_positive = [preprocess_text(doc) for doc in df_train[df_train['Polarity'] == 1]['Sentence']]\n",
    "processed_corpus_negative = [preprocess_text(doc) for doc in df_train[df_train['Polarity'] == 0]['Sentence']]\n",
    "\n",
    "all_words_positive = [word for doc in processed_corpus_positive for word in doc.split()]\n",
    "all_words_negative = [word for doc in processed_corpus_negative for word in doc.split()]\n",
    "\n",
    "word_counter_positive = Counter(all_words_positive)\n",
    "word_counter_negative = Counter(all_words_negative)\n",
    "\n",
    "num_words = 100\n",
    "positive_popular_words = [word for word, freq in word_counter_positive.most_common(num_words)]\n",
    "negative_popular_words = [word for word, freq in word_counter_negative.most_common(num_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(sentence):\n",
    "    words = sentence.split()\n",
    "    return len(words)\n",
    "\n",
    "def count_words_if_present(text, words_to_check):\n",
    "    text_words = text.split()\n",
    "    \n",
    "    if any(word in text_words for word in words_to_check):\n",
    "        return len(text_words)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def length_of_review(data):\n",
    "    data['word_count_in_review'] = [count_words(sentence) for sentence in data['Sentence']]\n",
    "    data['character_count_in_review'] = [len(sentence) for sentence in data['Sentence']]\n",
    "    data['frequent_positive_words'] = [count_words_if_present(word, positive_popular_words) for word in data['processed_text']]\n",
    "    data['frequent_negative_words'] = [count_words_if_present(word, negative_popular_words) for word in data['processed_text']]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency - Inverse Document Frequency (TF-IDF) is applied on the 3000 most popular words in the corpus to indicate how popular / frequent they are in the dataset. The popular words are converted to vectors and the frequency of each word in the dataset is calculated. Focusing on the most popular words allows the dimensionality of the data to be reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = [preprocess_text(doc) for doc in df_train['Sentence']]\n",
    "\n",
    "all_words = [word for doc in processed_corpus for word in doc.split()]\n",
    "word_counter = Counter(all_words)\n",
    "\n",
    "num_popular_words = 3000\n",
    "popular_words = [word for word, freq in word_counter.most_common(num_popular_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(data):\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    tfidf = TfidfVectorizer(vocabulary = popular_words)\n",
    "    X = tfidf.fit_transform(data)\n",
    "\n",
    "    X_array = X.toarray()\n",
    "\n",
    "    df = pd.DataFrame(X_array)\n",
    "    df.columns = tfidf.get_feature_names_out()\n",
    "\n",
    "    new_data = pd.concat([data, df], axis = 1)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "def tfidf_vectorized_df(data):\n",
    "    \n",
    "    vectorized_df = tfidf_vectorizer(data['processed_text'])\n",
    "    vectorized_df.drop(columns = ['processed_text'], inplace = True)\n",
    "    data = vectorized_df.merge(data, how = 'inner', left_index = True, right_index = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pipeline function where all feature engineering functions are applied to the training data, to generate the feature columns, which would act as inputs to the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data, function_list):\n",
    "    for function in function_list:\n",
    "        data = function(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_list = [count_special_characters,\n",
    "                preprocessing_df,\n",
    "                length_of_review,\n",
    "                tfidf_vectorized_df\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = pipeline(df_train, function_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not</th>\n",
       "      <th>n't</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>phone</th>\n",
       "      <th>work</th>\n",
       "      <th>'s</th>\n",
       "      <th>food</th>\n",
       "      <th>place</th>\n",
       "      <th>servic</th>\n",
       "      <th>...</th>\n",
       "      <th>flag</th>\n",
       "      <th>subtl</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>special_character_count</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>word_count_in_review</th>\n",
       "      <th>character_count_in_review</th>\n",
       "      <th>frequent_positive_words</th>\n",
       "      <th>frequent_negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>wow ... love place</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>crust not good</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not tasti textur nasti</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>15</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>select menu great price</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        not  n't      good     great  phone  work   's  food     place  \\\n",
       "0  0.000000  0.0  0.000000  0.000000    0.0   0.0  0.0   0.0  0.434918   \n",
       "1  0.357557  0.0  0.392351  0.000000    0.0   0.0  0.0   0.0  0.000000   \n",
       "2  0.256631  0.0  0.000000  0.000000    0.0   0.0  0.0   0.0  0.000000   \n",
       "3  0.000000  0.0  0.000000  0.000000    0.0   0.0  0.0   0.0  0.000000   \n",
       "4  0.000000  0.0  0.000000  0.345649    0.0   0.0  0.0   0.0  0.000000   \n",
       "\n",
       "   servic  ...  flag  subtl  \\\n",
       "0     0.0  ...   0.0    0.0   \n",
       "1     0.0  ...   0.0    0.0   \n",
       "2     0.0  ...   0.0    0.0   \n",
       "3     0.0  ...   0.0    0.0   \n",
       "4     0.0  ...   0.0    0.0   \n",
       "\n",
       "                                            Sentence  Polarity  \\\n",
       "0                           Wow... Loved this place.         1   \n",
       "1                                 Crust is not good.         0   \n",
       "2          Not tasty and the texture was just nasty.         0   \n",
       "3  Stopped by during the late May bank holiday of...         1   \n",
       "4  The selection on the menu was great and so wer...         1   \n",
       "\n",
       "   special_character_count                                     processed_text  \\\n",
       "0                        2                                 wow ... love place   \n",
       "1                        1                                     crust not good   \n",
       "2                        1                             not tasti textur nasti   \n",
       "3                        4  stop late may bank holiday rick steve recommen...   \n",
       "4                        1                            select menu great price   \n",
       "\n",
       "   word_count_in_review  character_count_in_review  frequent_positive_words  \\\n",
       "0                     4                         24                        4   \n",
       "1                     4                         18                        3   \n",
       "2                     8                         41                        4   \n",
       "3                    15                         87                        9   \n",
       "4                    12                         59                        4   \n",
       "\n",
       "   frequent_negative_words  \n",
       "0                        4  \n",
       "1                        3  \n",
       "2                        4  \n",
       "3                        9  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 3008 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Logistic Regression\n",
    "\n",
    "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is selected as the model of choice for this binary classification use case, given its ability to work with high dimensional data & sparse matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_input.drop(columns = ['Sentence', 'Polarity', 'processed_text'])\n",
    "y = model_input['Polarity']\n",
    "X.columns = X.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not</th>\n",
       "      <th>n't</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>phone</th>\n",
       "      <th>work</th>\n",
       "      <th>'s</th>\n",
       "      <th>food</th>\n",
       "      <th>place</th>\n",
       "      <th>servic</th>\n",
       "      <th>...</th>\n",
       "      <th>ceas</th>\n",
       "      <th>favourit</th>\n",
       "      <th>colour</th>\n",
       "      <th>flag</th>\n",
       "      <th>subtl</th>\n",
       "      <th>special_character_count</th>\n",
       "      <th>word_count_in_review</th>\n",
       "      <th>character_count_in_review</th>\n",
       "      <th>frequent_positive_words</th>\n",
       "      <th>frequent_negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        not  n't      good     great  phone  work   's  food     place  \\\n",
       "0  0.000000  0.0  0.000000  0.000000    0.0   0.0  0.0   0.0  0.434918   \n",
       "1  0.357557  0.0  0.392351  0.000000    0.0   0.0  0.0   0.0  0.000000   \n",
       "2  0.256631  0.0  0.000000  0.000000    0.0   0.0  0.0   0.0  0.000000   \n",
       "3  0.000000  0.0  0.000000  0.000000    0.0   0.0  0.0   0.0  0.000000   \n",
       "4  0.000000  0.0  0.000000  0.345649    0.0   0.0  0.0   0.0  0.000000   \n",
       "\n",
       "   servic  ...  ceas  favourit  colour  flag  subtl  special_character_count  \\\n",
       "0     0.0  ...   0.0       0.0     0.0   0.0    0.0                        2   \n",
       "1     0.0  ...   0.0       0.0     0.0   0.0    0.0                        1   \n",
       "2     0.0  ...   0.0       0.0     0.0   0.0    0.0                        1   \n",
       "3     0.0  ...   0.0       0.0     0.0   0.0    0.0                        4   \n",
       "4     0.0  ...   0.0       0.0     0.0   0.0    0.0                        1   \n",
       "\n",
       "   word_count_in_review  character_count_in_review  frequent_positive_words  \\\n",
       "0                     4                         24                        4   \n",
       "1                     4                         18                        3   \n",
       "2                     8                         41                        4   \n",
       "3                    15                         87                        9   \n",
       "4                    12                         59                        4   \n",
       "\n",
       "   frequent_negative_words  \n",
       "0                        4  \n",
       "1                        3  \n",
       "2                        4  \n",
       "3                        9  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 3005 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is split into training & validation sets, to enable model evaluation during hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning : Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is hyper parameter tuned using optuna. Optuna chooses the next value in the hyper parameter search space, depending on model performance in the previous run, allowing the search space to be scanned rather intentionally. The hyper parameter tuning is allowed to run for 1000 iterations, to get a good model fit.\n",
    "\n",
    "Cross-validation is applied to ensure that the model does not overfit and memorize noise from the training data. The hyper parameter tuning is intended to optimize for macro F-1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    C = trial.suggest_float('C', 1e-10, 1e10, log = True)\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 1e-10, 1, log = True)\n",
    "    \n",
    "    classifier = LogisticRegression(C = C, \n",
    "                                    solver = solver, \n",
    "                                    max_iter = 5000, \n",
    "                                    l1_ratio = l1_ratio,\n",
    "                                   )\n",
    "    \n",
    "    ## F-1 macro is the used as the scoring variable - so that an adequate accuracy can be obtained for both \n",
    "    ## positive & negative classes\n",
    "    \n",
    "    scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring = 'f1_macro')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials=1000)  \n",
    "\n",
    "print(f'Number of finished trials: {len(study.trials)}')\n",
    "print(f'Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f'  Value (macro F1 score): {-trial.value}')\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best set of hyper parameter values, post hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammadananjaved/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.8146379180758552, l1_ratio=0.0003371579751677212,\n",
       "                   max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.8146379180758552, l1_ratio=0.0003371579751677212,\n",
       "                   max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.8146379180758552, l1_ratio=0.0003371579751677212,\n",
       "                   max_iter=5000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    C = 1.8146379180758552,\n",
    "    solver = 'lbfgs',\n",
    "    l1_ratio = 0.0003371579751677212,\n",
    "    max_iter = 5000\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       857\n",
      "           1       0.96      0.93      0.95       823\n",
      "\n",
      "    accuracy                           0.95      1680\n",
      "   macro avg       0.95      0.95      0.95      1680\n",
      "weighted avg       0.95      0.95      0.95      1680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, lr_model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold tuning was performed to account for the imbalance in positive / negative class distributions, and to make the model more receptive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "thresholds = [i/100 for i in range(100)]\n",
    "\n",
    "y_prob = lr_model.predict_proba(X_train)[:,1]\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred = [1 if p > thresh else 0 for p in y_prob]\n",
    "    \n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    precision = precision_score(y_train, y_pred)\n",
    "    recall = recall_score(y_train, y_pred)\n",
    "    f1 = f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6lklEQVR4nO3dd1QU198G8GfpRZqAFAtgQSxREWLBnwUL9m7AEntDTSxojEZjiUYTu8beMMaGvSQ27D32bmygoIIKKKD03fv+wcvqSpHFhaE8n3M4MnfaswO4371zZ0YmhBAgIiIiKiS0pA5AREREpEksboiIiKhQYXFDREREhQqLGyIiIipUWNwQERFRocLihoiIiAoVFjdERERUqLC4ISIiokKFxQ0REREVKixuKEfWrVsHmUym/NLR0YGdnR26du2Khw8fSh0PAODo6Ig+ffpIHSOd9+/f47fffoOrqyuKFSsGY2Nj1KhRAzNmzMD79++ljpdtM2bMwO7du9O1nzhxAjKZDCdOnMjzTGmCgoLw3XffwdnZGYaGhjAyMkKVKlUwceJEPH/+XLlco0aNULVqVclyfolNmzZhwYIFubb9nPz9nDt3DlOmTMHbt2/TzWvUqBEaNWqkkWxpmjRpAl9fX+V02u9e2pe2tjasra3Rtm1bXL58OcNtCCGwadMmNG7cGBYWFtDX10fZsmUxbNgwhIaGZrrvffv2oW3btrCxsYGenh6KFy+OJk2aYOPGjUhOTgYAvHnzBubm5hn+nVAuE0Q54O/vLwAIf39/cf78eXH8+HExffp0YWhoKEqUKCGioqKkjiiuXr0qHj16JHUMFeHh4aJq1arC0NBQ/Pjjj+Lw4cPi8OHDYty4ccLQ0FBUrVpVhIeHSx0zW4yNjUXv3r3TtUdHR4vz58+L6OjovA8lhNi3b58wNjYWDg4OYvbs2eLIkSPi6NGjYsGCBaJatWqiRo0aymUbNmwoqlSpIknOL9W6dWvh4OCQa9vPyd/P7NmzBQARHBycbt6dO3fEnTt3NJROiN27dwt9fX3x7NkzZdvx48cFADFjxgxx/vx5cerUKbFw4UJRvHhxYWRkJB48eKCyDblcLnx8fAQA0a1bN7F7925x/PhxsXDhQlGqVClhbm4uzpw5o7KOQqEQffr0EQBEq1atxIYNG8TJkyfF3r17xahRo4SpqalYsGCBcvkpU6aI8uXLi8TERI29dvo8FjeUI2nFzaVLl1Tap06dKgCItWvXSpRMWikpKSIhISHT+V5eXkJHR0ecPn063bzTp08LHR0d0bx589yMmKHP5c5IZsWNlIKCgoSxsbFwdXUVb9++TTdfoVCIHTt2KKfzorhRKBQiLi5O49vNreLmS7JmVdxoWq1atUTXrl1V2tKKm23btqm0//nnnwKAmDRpkkr7jBkzBADx22+/pdt+eHi4cHBwEDY2NuLNmzfK9t9//10AEFOnTs0wV1hYmMrfd3h4uNDR0REbN25U9yXSF2BxQzmSWXHzzz//CABi5syZKu2XLl0Sbdu2FRYWFkJfX1/UqFFDBAQEpNvus2fPxMCBA0WpUqWErq6usLOzE507d1bpzYiOjhajR48Wjo6OQldXV9jb24sRI0aId+/eqWzLwcFB+eb76tUroaurKyZOnJhun/fu3RMAxMKFC5VtYWFhYtCgQaJkyZJCV1dXODo6iilTpojk5GTlMsHBwQKA+P3338W0adOEo6Oj0NbWFgcOHMjwmF26dEkAEIMHD87kqAoxaNAgAUBcvnxZ2QZADBs2TCxfvlxUqFBB6OnpiUqVKonNmzenW/9Lc8fHxws/Pz9RvXp1YWpqKiwsLESdOnXE7t27VfYDIN1Xw4YNhRAf3mCOHz+uXL53797C2NhYPHz4ULRs2VIYGxuLUqVKCT8/v3RFVWhoqOjcubMoVqyYMDMzE927dxcXL15U9hRm5bvvvhMAxPnz57NcLk1acXPx4kXxv//9TxgaGgonJycxc+ZMIZfLlctl97ikHZthw4aJZcuWCRcXF6GrqyuWLVsmhEj9FF+rVi1hYWEhTExMhKurq1i9erVQKBTptrNx40ZRp04dYWxsLIyNjUX16tXF6tWrlbkz+hmkSUxMFNOmTRMVK1YUenp6wsrKSvTp00e8evVKZR8ODg6idevWYseOHaJGjRpCX19f/Pjjj8p5HxevcrlcTJs2TTg7OwsDAwNhZmYmvvrqK2UvxeTJkzPMlPZ70LBhQ+XvSJqEhAQxdepU4eLiIvT19UXx4sVFo0aNxNmzZ7P8uV29elUAEP/8849Ke2bFzZ07d9L97SUmJgoLCwtRqVKlDI+/EEJs2rRJABBz5swRQgiRlJQkihcvLlxcXDJdJyMtW7YU9evXz/by9OV0culsFxVRwcHBAABnZ2dl2/Hjx9GiRQvUrl0by5cvh5mZGbZs2QIfHx/ExcUpz+s/f/4cX3/9NZKTk/HTTz+hWrVqiIyMxKFDh/DmzRvY2NggLi4ODRs2xLNnz5TL3LlzB5MmTcKtW7dw5MgRyGSydLmsra3Rpk0b/Pnnn5g6dSq0tD4MN/P394eenh569OgBAAgPD0etWrWgpaWFSZMmoVy5cjh//jymT5+OJ0+ewN/fX2XbixYtgrOzM+bMmQNTU1NUqFAhw2MTGBgIAOjQoUOmx69Dhw5YuXIlAgMD4ebmpmzfu3cvjh8/jl9++QXGxsZYunQpunXrBh0dHXTp0kVjuRMTExEVFYUxY8agZMmSSEpKwpEjR9CpUyf4+/ujV69eAIDz58+jcePG8PT0xM8//wwAMDU1zfR1AUBycjLatWuH/v37Y/To0Th16hSmTZsGMzMzTJo0CUDqeCRPT09ERUXh999/R/ny5XHw4EH4+Phkue00hw8fho2NDerUqZOt5dOOW48ePTB69GhMnjwZu3btwvjx42Fvb698vdk9Lml2796N06dPY9KkSbC1tUWJEiUAAE+ePMHgwYNRpkwZAMCFCxfw/fff4/nz58pjAACTJk3CtGnT0KlTJ4wePRpmZma4ffs2nj59CgBYunQpBg0ahMePH2PXrl0q+1YoFGjfvj1Onz6NsWPHwsPDA0+fPsXkyZPRqFEjXL58GYaGhsrlr169inv37mHixIlwcnKCsbFxhsdp1qxZmDJlCiZOnIgGDRogOTkZ//33n3J8zYABAxAVFYU//vgDO3fuhJ2dHQCgcuXKGW4vJSUFLVu2xOnTpzFy5Eg0btwYKSkpuHDhAkJCQuDh4ZHpz+zvv/+GtrY2GjRokOkyH8vo/6UrV67gzZs3GDRoUIb/ZwBA27ZtoaWlhcDAQIwePRqXL19GVFQUBg4cmOk6GWnUqBHGjx+Pt2/fwtzcPNvr0ReQurqigimt5+bChQsiOTlZxMbGioMHDwpbW1vRoEEDlZ4CFxcX4erqqtImhBBt2rQRdnZ2yk/I/fr1E7q6uuLu3buZ7nfmzJlCS0srXY/R9u3bBQCxf/9+Zdunnzz37t0rAIjDhw8r21JSUoS9vb3o3Lmzsm3w4MGiWLFi4unTpyr7mDNnjgCgHDeQ1gNSrlw5kZSU9LlDJnx9fQUA8d9//2W6TFov0pAhQ5RtAIShoaFK71VKSopwcXER5cuXz9XcKSkpIjk5WfTv31+4urqqzMvstFRmPTcAxNatW1WWbdWqlahYsaJyesmSJQJAut6vwYMHZ6vnxsDAQNSpUyfLZT6W1gPy77//qrRXrlw5y9ODWR0XAMLMzOyz487kcrlITk4Wv/zyi7C0tFT2BAQFBQltbW3Ro0ePLNfP7LTU5s2bBQCV029CfOg5XLp0qbLNwcFBaGtri/v376fbzqd/P23atFEZr5SRrE5Lfdpzs379egFArFq1KsttZqRly5bCxcUlXXva715AQIBITk4WcXFx4uzZs6JixYqicuXKKqeXtmzZIgCI5cuXZ7kvGxsbUalSJbXW+VRgYGCGv9eUe3i1FH2ROnXqQFdXFyYmJmjRogUsLCywZ88e6Oikdgo+evQI//33n7JXJCUlRfnVqlUrhIWF4f79+wCAAwcOwNPTE5UqVcp0f3///TeqVq2KGjVqqGyrefPmn71Cp2XLlrC1tVXpwTh06BBevHiBfv36qezD09MT9vb2Kvto2bIlAODkyZMq223Xrh10dXXVO3CZEEIAQLpPhU2aNIGNjY1yWltbGz4+Pnj06BGePXum0dzbtm1DvXr1UKxYMejo6EBXVxdr1qzBvXv3vui1yWQytG3bVqWtWrVqyt6ItIxpv0sf69at2xftOyu2traoVatWlrkA9Y5L2pU3nzp27BiaNm0KMzMzaGtrQ1dXF5MmTUJkZCRevXoFILWHTy6XY9iwYTl6PX///TfMzc3Rtm1bld+DGjVqwNbWNt3fSLVq1VR6NDJTq1Yt3LhxA0OHDsWhQ4cQExOTo3xpDhw4AAMDA5W/vex68eKFsjcsIz4+PtDV1YWRkRHq1auHmJgY/PPPPznqNRFCqNVLk5G0rB9fqUe5i8UNfZH169fj0qVLOHbsGAYPHox79+6pvBG9fPkSADBmzBjo6uqqfA0dOhQAEBERAQB4/fo1SpUqleX+Xr58iZs3b6bblomJCYQQym1lREdHBz179sSuXbuUXenr1q2DnZ0dmjdvrrKPffv2pdtHlSpVVPKmSet+/5y0UxFpXeQZefLkCQCgdOnSKu22trbplk1ri4yM1FjunTt3wtvbGyVLlsSGDRtw/vx5XLp0Cf369UNCQkK2XmdmjIyMYGBgoNKmr6+vst3IyEiVIi5NRm0ZKVOmTJbHNyOWlpbp2vT19REfH6+cVve4ZHRsL168CC8vLwDAqlWrcPbsWVy6dAkTJkwAAOX+Xr9+DQCf/VvIzMuXL/H27Vvo6eml+10IDw/P8e/v+PHjMWfOHFy4cAEtW7aEpaUlmjRpkukl1p/z+vVr2Nvbq5wizq74+Ph0v0sf+/3333Hp0iWcPHkSEyZMwMuXL9GhQwckJiYql8nO3+P79+8RERGh/HvMzjoZScv68e8U5S6OuaEvUqlSJbi7uwMAPD09IZfLsXr1amzfvh1dunSBlZUVgNT/GDt16pThNipWrAggdVxMWi9EZqysrGBoaIi1a9dmOj8rffv2xezZs5Vjfvbu3YuRI0dCW1tbZRvVqlXDr7/+muE27O3tVaaz+6muWbNm+Omnn7B79+50PRNp0u6H0axZM5X28PDwdMumtaW9OWsi94YNG+Dk5ISAgACV+R+/KeQmS0tLXLx4MV17Rq8/I82bN8cff/yBCxcuqDXu5nPUPS4ZHdstW7ZAV1cXf//9t8ob86f3QLG2tgYAPHv2LF2Rmx1WVlawtLTEwYMHM5xvYmLy2awZ0dHRgZ+fH/z8/PD27VscOXIEP/30E5o3b47Q0FAYGRmpldPa2hpnzpyBQqFQu8CxsrJCVFRUpvPLli2r/H+pQYMGMDQ0xMSJE/HHH39gzJgxAAA3NzdYWFhg7969mDlzZobHYe/evVAoFMq/R3d3dxQvXhx79uzJdJ2MpGX93P9PpDnsuSGNmjVrFiwsLDBp0iQoFApUrFgRFSpUwI0bN+Du7p7hV9p/ti1btsTx48eVp6ky0qZNGzx+/BiWlpYZbsvR0THLfJUqVULt2rXh7++PTZs2ITExEX379k23j9u3b6NcuXIZ7uPTIiG73N3d4eXlhTVr1uDs2bPp5p85cwZr165FixYtVAYTA8DRo0eVvWAAIJfLERAQgHLlyik/4Wsit0wmg56ensp/2uHh4dizZ0+6ZT/t3dCEhg0bIjY2FgcOHFBp37JlS7bWHzVqFIyNjTF06FBER0enmy+ESDcANzvUOS5ZbUNHR0elkI6Pj8dff/2lspyXlxe0tbWxbNmyLLeX2fFv06YNIiMjIZfLM/w9SPsw8SXMzc3RpUsXDBs2DFFRUcoeR319feXr+pyWLVsiISEB69atU3v/Li4uCAoKyvbyY8eORfny5fHbb78hNjYWAKCnp4cffvgB9+7dw+zZs9Ot8+rVK4wfPx42NjYYMGAAAEBXVxc//vgj/vvvP0ybNi3Dfb169Srd33da1swGV5PmseeGNMrCwgLjx4/H2LFjsWnTJnz77bdYsWIFWrZsiebNm6NPnz4oWbIkoqKicO/ePVy9ehXbtm0DAPzyyy84cOAAGjRogJ9++glfffUV3r59i4MHD8LPzw8uLi4YOXIkduzYgQYNGmDUqFGoVq0aFAoFQkJCcPjwYYwePRq1a9fOMmO/fv0wePBgvHjxAh4eHun+s//ll18QGBgIDw8PDB8+HBUrVkRCQgKePHmC/fv3Y/ny5Tk+ZbB+/Xo0bdoUXl5eGD58OJo0aQIgdSzGwoUL4eLikuF/9lZWVmjcuDF+/vln5dVS//33n8qbviZyt2nTBjt37sTQoUPRpUsXhIaGYtq0abCzs0t35+mvvvoKJ06cwL59+2BnZwcTE5MvfuPs3bs35s+fj2+//RbTp09H+fLlceDAARw6dAgAPvsJ38nJSdkrV6NGDXz33XdwdXUFANy9exdr166FEAIdO3ZUK5c6xyUzrVu3xrx589C9e3cMGjQIkZGRmDNnjrIgSOPo6IiffvoJ06ZNQ3x8PLp16wYzMzPcvXsXERERmDp1KoDU479z504sW7YMbm5u0NLSgru7O7p27YqNGzeiVatWGDFiBGrVqgVdXV08e/YMx48fR/v27dV+/UDqlUNVq1aFu7s7rK2t8fTpUyxYsAAODg7KKwS/+uorAMDChQvRu3dv6OrqomLFiul6i4DUcVT+/v7w9fXF/fv34enpCYVCgX///ReVKlVC165dM83SqFEjrF27Fg8ePMjWeCFdXV3MmDED3t7eWLhwISZOnAgA+PHHH3Hjxg3lvz4+PjAzM8PNmzcxe/ZsxMbG4u+//4aZmZlyW2kF0eTJk3Hx4kV0794dpUuXRnR0NE6dOoWVK1di6tSpqFevnnKdCxcuwNLSUnl8KA9IOpyZCqzM7nMjROo9QcqUKSMqVKggUlJShBBC3LhxQ3h7e4sSJUoIXV1dYWtrKxo3bpzuqoPQ0FDRr18/YWtrq7yHjbe3t3j58qVymXfv3omJEycq7+GRdr+NUaNGqVxR9OnVHmmio6OFoaFhlldqvH79WgwfPlw4OTkJXV1dUbx4ceHm5iYmTJigvJ9O2lVHs2fPVuvYvXv3TsyYMUPUqFFDGBkZCSMjI1GtWjUxffr0dPfqEeLDfVOWLl0qypUrJ3R1dYWLi0uGNwXTRO7ffvtNODo6Cn19fVGpUiWxatUq5T1MPnb9+nVRr149YWRklO373Hwqo+2GhISITp06iWLFigkTExPRuXNnsX//fgFA7NmzJ8tjm+bx48di6NChonz58kJfX18YGhqKypUrCz8/P5UreTK7iV/v3r3TXYmU3eOS9vPKyNq1a0XFihWFvr6+KFu2rJg5c6ZYs2ZNhlcYrV+/Xnz99dfCwMBAFCtWTLi6uqpcLRYVFSW6dOkizM3NhUwmU8mRnJws5syZI6pXr65c38XFRQwePFg8fPhQuVzafW4y8unfz9y5c4WHh4ewsrISenp6okyZMqJ///7iyZMnKuuNHz9e2NvbCy0trc/e5yY+Pl5MmjRJef8mS0tL0bhxY3Hu3LkMM6WJjo4WxYoVE7NmzVJpz+w+N2lq164tLCwsVG7wqFAoxMaNG0WjRo2Eubm50NPTE05OTmLIkCHprjz82J49e0Tr1q2FtbW10NHRERYWFsLT01MsX75c5W7ECoVCODg4iO+//z7L10SaJRPi/y/PIKJ8SSaTYdiwYVi8eLHUUSQzY8YMTJw4ESEhITnuNaPC5fvvv8fRo0dx586dL76aKTcdPXoUXl5euHPnDlxcXKSOU2TwtBQR5StpRZyLiwuSk5Nx7NgxLFq0CN9++y0LG1KaOHEi1q9fjx07dihvZJkfTZ8+Hf369WNhk8dY3BBRvmJkZIT58+fjyZMnSExMRJkyZfDjjz8qx0kQAam3B9i4cSPevHkjdZRMvXnzBg0bNlTe9oLyDk9LERERUaHCS8GJiIioUGFxQ0RERIUKixsiIiIqVIrcgGKFQoEXL17AxMQkX18+SERERB8IIRAbG5utZ5IVueLmxYsXOXpeCxEREUkvNDT0s7eFKHLFTdptwENDQ2FqaipxGiIiIsqOmJgYlC5dOsPHeXyqyBU3aaeiTE1NWdwQEREVMNkZUsIBxURERFSosLghIiKiQoXFDRERERUqLG6IiIioUGFxQ0RERIUKixsiIiIqVFjcEBERUaHC4oaIiIgKFRY3REREVKiwuCEiIqJCRdLi5tSpU2jbti3s7e0hk8mwe/fuz65z8uRJuLm5wcDAAGXLlsXy5ctzPygREREVGJIWN+/fv0f16tWxePHibC0fHByMVq1aoX79+rh27Rp++uknDB8+HDt27MjlpERERFRQSPrgzJYtW6Jly5bZXn758uUoU6YMFixYAACoVKkSLl++jDlz5qBz5865lJKIiPIdeRKQEi91Cs169xwI+gcQCqmT5FhSsoBMBujqyACXboBpGUlyFKingp8/fx5eXl4qbc2bN8eaNWuQnJwMXV3ddOskJiYiMTFROR0TE5PrOYmICrSoB0BcuPrryZOAmysBrVx+a3l6BIh/nbv7ILU9iTJH1w1dUN/pKWa3DQTs6rC4yY7w8HDY2NiotNnY2CAlJQURERGws7NLt87MmTMxderUvIpIRKR5QgBCnvn8t4+Bp4Gpy32J8IvAvQ1ftg0qkl7FGsN1/mC8jTfEvyGl0KjcE7SWME+BKm4AQCaTqUyL//9j/rQ9zfjx4+Hn56ecjomJQenSpXMvIBHlD+/CgPcvPr9cUixwZz0gy6cXj766Bry6KnWK/MvBC8jk//8CKeENUK4tYFlV6iRqKQGgV/BzLFofgbKl9WDTegpgWUWyPAWquLG1tUV4uGpX6atXr6CjowNLS8sM19HX14e+vn5exCOi3BD1AHh+JvvLv7kPXJqVe3mKkq/Hqr+OEIBJqdQ36Nwk0wZMSheuwqaAm7UyBcYlT+LHH+vBzMxA0iwFqripW7cu9u3bp9J2+PBhuLu7ZzjehoiySSEH3jwEkI3TGiHHgKh7qW8uAHBtUeq/WrnwN6hI1vw2CzK7OpmPZ4l7BVTtn1pYfAltfcDRC9Az+bLtUKG2desdJCXJ8e231ZRt+vo6mDGjiYSpPpC0uHn37h0ePXqknA4ODsb169dRvHhxlClTBuPHj8fz58+xfv16AICvry8WL14MPz8/DBw4EOfPn8eaNWuwefNmqV4CUdainwBhF4CriwAt7Q8FQX4iT0zN+KXyayFSY9jnlxFywLwC4Ng89/PkhEwLsHBO/R0iklBCQgpGjTqI5cuvwNBQB66utqhSpYTUsdKRtLi5fPkyPD09ldNpY2N69+6NdevWISwsDCEhIcr5Tk5O2L9/P0aNGoUlS5bA3t4eixYt4mXgBV1yHBAfobntRdwGQk9o5o0g8h7weA+gb67+uolvv3z/BU2Jmrmz3XfPAPcx2f85aOkATi0BY9vcyUNUBD14EAlv7224ceMlACA+PgWbN9/G9OmNJU6WnkyILx1eX7DExMTAzMwM0dHRMDU1lTpO0RUTApz/BXiwDUji5fn5hm2t7A0CFClApZ6AvlnqtIEFYFEhd7MRkWQ2bbqFwYP/xrt3SQAAAwMdLF7cEv36uWZ6QY+mqfP+XaDG3FA+lvweSI5Pvarj9lrgfgBQzD7z5d9l4yqW/MbMCdDSU3+96CCg9gTAulrqaY/8eGoKALR18+8VQ0Qkibi4ZIwYcQCrV19Ttrm4WGHbtm9QtWr+Ox2VhsUNpZInAS/OA4oU9dYTCmCHV8bz1C1gnLtAY08ESXkPOHtr5gZSMi3A5mtA1/DLt0VEVEDcu/ca3t7bcfv2K2Vb797VsWRJKxgb5+CDXh5icVMUCQGkJKR+H3UPuLUKuJFLDyA1tsv6bqXO3kCdiYCBee7sn4iI1CaXK9CxYwDu348EABgZ6WLp0lbo3buGtMGyicVNYSEEEHkXiLwDPNgO6GTSy5AUCzzalXs5yrZJHUhbbTBQvgOgVyz39kVERLlCW1sLq1a1RaNGf6JyZWsEBHRB5crWUsfKNhY3hcHjfcDudprZln09oHRD9dczdQK+6scxG0REBZQQQmVwcP36Dti3rxsaNXKEkVHBupcci5uC7vXNnBc2pg6AWdnUB9BV8019gqthcc3mIyKifE0IgTVrruGffx5ixw5vaGl9KHBatSqYV0GyuCno1ldXndY1Bqr0AUp7AlZZPJvEpAwHyBIRFXGxsYnw9f0HmzbdAgD8/vsZjB9fX+JUX47FTUG2vobqdO2fgP/9KkkUIiIqWK5fD4e39zY8fBilbAsLe5fu9FRBxOKmoBECODYcuLE09TLsNMa2LGyIiOizhBBYvvwyRo06hMREOQDA1FQfq1a1hbe3dE/y1iQWNwVFTAhwZAgQvD/j+f0f520eIiIqcKKjEzBw4D5s23ZX2ebmZoeAgC4oV67wjLlkcZNfhZ4EbixLvR/N4z1ZLzsgGNA1yptcRERUIF2+/AI+PtsRFPRG2TZ8eC3MmtUM+vqFqxwoXK+msBAKYGujrJcp7gJ0Pcurm4iIKFtWrLisLGzMzQ2wdm07dOxYSeJUuYPFTX7z9AiwvVnm8+tMBOr8DGjn71tfExFR/rJgQQucPRsKExN9BAR0gaOjudSRcg2Lm/zkwq/A2YmqbdbVgM6HAW19PqKAiIiyLTY2ESYm+sppY2M9HDr0LWxsikFPL58+wFdDeDvZ/OJ9ePrCBgB6XgOMbVjYEBFRtgghMHfuOZQtuwiPH0epzCtd2qzQFzYAi5v8QZECrHJQbWu/Gxgt+DgDIiLKtsjIOLRrtwVjxgQiIiIOPj7bkZiYInWsPMfTUvlB5F1AnvRhuvYEoHx76fIQEVGBc/ZsCLp23YFnz2KUbc2alVV5nEJRweImP7izXnXafYw0OYiIqMBRKARmzTqLiROPQS4XAAArKyP89VdHtGhRXuJ00mBxkx/cWPLh+1rjOb6GiIiy5dWr9+jVaxcOHfpwI9eGDR2waVNn2NubSJhMWixupPbuReqN+tJUGyRdFiIiKjBOn34KH5/tCAt7BwCQyYCJExtg0qSG0NEp2uM1WdxI7W2Q6rSpQ8bLERERfeT9+2RlYWNjY4wNGzqhadOyEqfKH1jcSEkIIOCjR8vXHJFaehMREX1Gixbl8eOP9XD58gts2NAJtrbFpI6Ub7C4kdLuT66IKlZKmhxERJTvXb8ejurVbSD76EPw9OmNIZMB2tpF+zTUp3g0pBTzRHX6q/6SxCAiovxLLldg8uTjqFlzBZYsuaQyT0dHi4VNBnhEpPTxDfpGJQMGFtJlISKifOfFi1g0abIev/xyCkIAo0cfxn//RUgdK9/jaSmpCAG8vpH6vY4BoMUfBRERfXDo0CN8++0uRETEAQC0tWWYOrURnJ0tpQ1WAPAdVSpXF3z4XiGXLAYREeUvKSkK/PzzMfz221llW6lSpti8uTP+978yEiYrOFjcSCExBjjh92FakSxdFiIiyjdCQ6PRrdsOnD0bqmxr3boC/vyzAywtjSRMVrCwuJFC0N+q04NfSJODiIjyjYsXn6Nly42IiooHkDpY+LffmmDUqLpF8vlQX4LFjRSS4z58X64dUMxOuixERJQvODtbwsxMH1FR8XBwMMOWLV1Qpw5vEZITvFpKCuEXP3xfrp10OYiIKN8wNzdAQEAXeHtXwbVrg1nYfAEWN1K4terD97xKioioSNq79z6eP49Rafv665IICOgCCwtDiVIVDixu8po8SXXaqaU0OYiISBKJiSkYOfIg2rffgm7ddiAlRSF1pEKHxU1eu7P+w/fFSgJGJaTLQkREeSoo6A3q1VuLhQv/BQCcPh2CrVvvSJyq8OE5kbz28f1trKtLFoOIiPLW9u130b//XsTEJAIA9PW1MX9+c3TrVlXiZIUPi5u8lPAWiPz/Cl2mDXT8O8vFiYio4EtISIGf3yEsW3ZZ2VahQnFs3foNatSwlTBZ4cXiJq8IAWxt9GHa6itAxvsWEBEVZg8fRsLbezuuXw9XtnXrVhUrVrSBiYm+hMkKNxY3eUWR/OFZUgBg4yZdFiIiynXPn8fAzW0lYmNTLyQxMNDBH3+0RP/+rpDxw22u4oBiqTT+Q+oERESUi0qWNEXPntUAAC4uVrh4cQAGDKjJwiYPsOdGCqUaALq8hwERUWE3d25zWFkZ4Ycf6qFYMT2p4xQZLG6IiIg0YP36G9DWlqFHj2rKNgMDHUyd6ilhqqKJxQ0REdEXeP8+Cd99dwDr1l2HkZEuata0Q6VK1lLHKtI45oaIiCiHbt9+ha+/XoV1664DAOLikrFjxz1pQxF7boiIiNQlhMDatdfw/fcHEB+fAgAwNtbFihVtVE5LkTRY3BAREakhNjYRQ4b8g40bbynbqle3wdat38DZ2VLCZJSGxQ0REVE23bgRDm/v7XjwIFLZ5uvrhnnzmsPQUFfCZPQxFjdERETZkJKiQKdOWxEU9AYAYGKih9Wr28Hbu4rEyehTHFCcV+SJUicgIqIvoKOjhbVr20FLS4aaNe1w7dpgFjb5FHtu8sqd9R++FwrpchARUbYJIVTuKNywoSP27++ORo0coa/Pt9D8ij03eSU6+MP3BhxwRkSUnwkh8Mcf/6JTp61QKITKvObNy7OwyedY3Ejh6x+kTkBERJl4+zYBXbpsw/DhB7F793+YM+ec1JFITSw9iYiI/t/Fi8/h47MdT568VbZFRsZJF4hyhMUNEREVeUIIzJ9/AT/+eAQpKanjIi0sDPDnnx3Qtm1FidORuljcEBFRkRYVFY8+fXZj374HyjYPj9LYvLkzypQxkzAZ5RSLGyIiKrLOnQtF167bERoao2z78cd6mDbNE7q62hImoy/B4oaIiIqsVauuKgsbKysjrF/fAS1bVpA4FX0pya+WWrp0KZycnGBgYAA3NzecPn06y+U3btyI6tWrw8jICHZ2dujbty8iIyOzXCdfuDJX6gRERPSJP/5oiYoVLVG/fhlcvz6YhU0hIWlxExAQgJEjR2LChAm4du0a6tevj5YtWyIkJCTD5c+cOYNevXqhf//+uHPnDrZt24ZLly5hwIABeZxcTUmxqtMGFtLkICIq4qKjE1SmixXTw9GjvXDsWG+ULGkqUSrSNEmLm3nz5qF///4YMGAAKlWqhAULFqB06dJYtmxZhstfuHABjo6OGD58OJycnPC///0PgwcPxuXLl/M4uZrkSarTlpWlyUFEVETJ5QpMn34K5cotQnDwG5V5JUuaQkdH8hMZpEGS/TSTkpJw5coVeHl5qbR7eXnh3LmMb5jk4eGBZ8+eYf/+/RBC4OXLl9i+fTtat26d6X4SExMRExOj8iWpsplnJSIizXv58h1atNiIn38+jsjIePj4bEdSklzqWJSLJCtuIiIiIJfLYWNjo9JuY2OD8PDwDNfx8PDAxo0b4ePjAz09Pdja2sLc3Bx//PFHpvuZOXMmzMzMlF+lS5fW6OsgIqL869ixYNSosQJHjgQBALS0ZGjTxhna2rLPrEkFmeT9cB8/kAxI/5Cyj929exfDhw/HpEmTcOXKFRw8eBDBwcHw9fXNdPvjx49HdHS08is0NFSj+YmIKP+RyxWYPPk4mjZdj/DwdwAAO7tiOHq0FyZNaghtbcnf/igXSXYpuJWVFbS1tdP10rx69Spdb06amTNnol69evjhh9RnM1WrVg3GxsaoX78+pk+fDjs7u3Tr6OvrQ19fX/MvgIiI8qUXL2LRo8dOnDjxRNnm5VUOf/3VESVKGEsXjPKMZKWrnp4e3NzcEBgYqNIeGBgIDw+PDNeJi4uDlpZqZG3t1JssCSEyWoWIiIqQI0eCUKPGcmVho60tw4wZjXHgQA8WNkWIpDfx8/PzQ8+ePeHu7o66deti5cqVCAkJUZ5mGj9+PJ4/f47169cDANq2bYuBAwdi2bJlaN68OcLCwjBy5EjUqlUL9vb2Ur6UrAmF1AmIiIqExMQUvH6d+qDLkiVNsGVLF/zvf2UkTkV5TdLixsfHB5GRkfjll18QFhaGqlWrYv/+/XBwcAAAhIWFqdzzpk+fPoiNjcXixYsxevRomJubo3Hjxvj999+legnZs6yE1AmIiIqE1q2dMWZMXdy9G4E//+wAKysjqSORBGSiiJ3PiYmJgZmZGaKjo2Fqmgc3bHofDiz/aCxQtcFAs+W5v18ioiLg8uUXcHOzU7kQJSVFAS0tGbS0eEVUYaLO+zeHi+e2FNW7YaLJYmlyEBEVIsnJcvzww2F8/fUqrFhxRWWejo4WC5sijsVNXqrYFdDis0qJiL7E06dv0aDBOsyZcx4AMHLkQTx6FCVxKspP+E5LREQFxp49/6FPnz14+za1V1xXVwu//94U5crxmX30AYsbIiLK95KS5Bg7NhALF/6rbHNyMkdAQBd8/XVJCZNRfsTihoiI8rWgoDfw8dmOy5dfKNs6d66E1avbwdzcQMJklF+xuCEionzrzJkQtG69CTExiQAAPT1tzJ/fHEOGuGf6qB4iFjdERJRvValiDQsLA8TEJKJ8+eLYurULXF3TP2qH6GO8WoqIiPItCwtDBAR0wbffVsOVK4NY2FC2sOeGiIjyja1b76B+/TKwszNRttWuXQq1a5eSMBUVNOy5ISIiycXHJ2PQoH3w8dmOHj12Qi7nM/ko51jcEBGRpP77LwK1a6/GqlVXAQDHjz/Bnj33JU5FBRmLGyIiksxff92Au/tK3Lr1CgBgaKgDf//26NSpksTJqCDjmBsiIspz798n4fvvD8Df/7qyrUoVa2zd+g0qV7aWLhgVCixuiIgoT9258wre3ttx9+5rZVv//q5YtKgljIx0JUxGhQWLGyIiyjNPn77F11+vQnx8CgDA2FgXK1a0QY8e1SRORoUJx9wQEVGecXAwR69e1QEA1arZ4MqVQSxsSOPYc5PbEiKlTkBElK/Mn98cJUuaYMwYDxga8jQUaR57bnLbtSUfvhdy6XIQEeUxIQRWrLiMzZtvqbQbGuri558bsrChXMOem9wkBHDH/8O0XR3pshAR5aGYmEQMGrQPAQF3YGysCzc3ezg7W0odi4oI9tzkpnOTVaer9JEkBhFRXrp6NQw1a65AQMAdAMD798nYt4835aO8w56b3BT274fvdY0Bw+LSZSEiymVCCCxZcgmjRx9GUlLqaXgzM32sXcub8lHeYnGTm7Q+Ory9bkqXg4gol719m4D+/fdi5857yravv7ZHQEAXODlZSJiMiiIWN3lF30zqBEREueLixefw8dmOJ0/eKttGjaqD335rCj09bemCUZHF4oaIiHIsKUmOLl22IjQ0BgBgYWGAdes6oF27ihIno6KMA4qJiCjH9PS04e/fHjIZULduKVy/7svChiTHnhsiIlKLEAIymUw53aRJWRw69C0aNXKEri5PQ5H02HNDRETZolAIzJp1Fp07b4UQQmVes2blWNhQvsGeGyIi+qzXr9+jd+/dOHDgEQBg/vwL8POrK3EqooyxuCEioiydPv0UXbvuwIsXsQAAmQyIjU2UOBVR5ljcEBFRhhQKgZkzT2PSpBNQKFJPQ5UoYYwNGzqiWbNyEqcjyhyLm9wU/1rqBEREOfLy5Tv07LkLgYFByjZPT0ds3NgJdnYmEiYj+jwWN7klJhQIvyR1CiIitR07FowePXYiPPwdgNTTUJMnN8TEiQ2grc3rUCj/Y3GTW/72UZ3mHYqJqIBYu/aasrCxtS2GTZs6wdPTSeJURNmXoxI8JSUFR44cwYoVKxAbmzrA7MWLF3j37p1GwxVor65++N5zkepzpoiI8rGlS1ujfPniaNasLG7c8GVhQwWO2u+4T58+RYsWLRASEoLExEQ0a9YMJiYmmDVrFhISErB8+fLcyFmwxDwF5B9dSVDdV7osRESf8eZNPCwsDJXTpqb6OHmyD2xti0FLS5bFmkT5k9o9NyNGjIC7uzvevHkDQ8MPfwwdO3bE0aNHNRquwIq8qzqtrStNDiKiLKSkKDBx4jFUqPAHnj59qzLP3t6EhQ0VWGr33Jw5cwZnz56Fnp6eSruDgwOeP3+usWCFRq1xUicgIkrn2bMYdO++A6dPhwAAunbdgVOn+vAuw1QoqF3cKBQKyOXydO3Pnj2DiQkvD0xHx/DzyxAR5aH9+x+iV69diIyMBwBoa8vQqZMLr4SiQkPt3+RmzZphwYIFymmZTIZ3795h8uTJaNWqlSazERGRBiUnyzF2bCBat96kLGzKlDHD6dN98cMP9XgaigoNtXtu5s+fD09PT1SuXBkJCQno3r07Hj58CCsrK2zevDk3MhY8ivQ9W0REUgoJiUbXrttx/vwzZVu7dhXh798exYuzh5kKF7WLG3t7e1y/fh1btmzBlStXoFAo0L9/f/To0UNlgHGRdmqs1AmIiJT++ecBevbchTdvEgAAurpamDWrGUaMqA2ZjL01VPioXdycOnUKHh4e6Nu3L/r27atsT0lJwalTp9CgQQONBiyQtD8abG1dXbocRERIvSoqrbBxcjJHQEAXfP11SYlTEeUetYsbT09PhIWFoUSJEirt0dHR8PT0zHCwcdHz0Sehcm2li0FEBKB9exeMHFkboaExWL26HczNDaSORJSr1C5uhBAZdmNGRkbC2NhYI6EKDW19QMarD4gob/377zPUqlVS5f/q2bO9oK0t42koKhKyXdx06tQJQOrVUX369IG+vr5ynlwux82bN+Hh4aH5hERElC0JCSn44YfDWLz4ElaubIOBA92U83R0+EGLio5sFzdmZqkPfhRCwMTERGXwsJ6eHurUqYOBAwdqPiEREX3Wo0dR8PbehmvXwgEAw4cfRLNm5eDoaC5tMCIJZLu48ff3BwA4OjpizJgxPAVFRJRPBATcxsCB+xAbmwQA0NfXxsKFLeDgYCZxMiJpqD3mZvLkybmRg4iI1BQfn4yRIw9i5cqryraKFS2xdes3qFbNRsJkRNJSu7gBgO3bt2Pr1q0ICQlBUlKSyryrV69mshYREWnK/fsR8Pbejps3Xyrbvv22GpYta41ixfSyWJOo8FN7hNmiRYvQt29flChRAteuXUOtWrVgaWmJoKAgtGzZMjcyEhHRR44dC4ab20plYWNoqIO1a9th/foOLGyIkIPiZunSpVi5ciUWL14MPT09jB07FoGBgRg+fDiio6NzI2PBIhTA6+tSpyCiQqx6dRvlIxMqV7bGpUsD0bevKy/zJvp/ahc3ISEhyku+DQ0NERsbCwDo2bMnny0FAM9Of/henihdDiIqtCwtjbBlSxcMGOCKixcHoEqVEp9fiagIUbu4sbW1RWRkJADAwcEBFy5cAAAEBwdDCKHZdAVR3Ifz39DlFWVE9GWEEPjrrxsID3+n0u7hURqrVrWDsTFPQxF9Su3ipnHjxti3bx8AoH///hg1ahSaNWsGHx8fdOzYUeMBC7R606ROQEQF2Lt3Sejdezd69dqNb7/dCblcIXUkogJB7aulVq5cCYUi9Q/M19cXxYsXx5kzZ9C2bVv4+vpqPCARUVF08+ZLeHtvw/37qT3lR48G48CBR2jTxlniZET5n9rFjZaWFrS0PnT4eHt7w9vbGwDw/PlzlCzJJ80SEeWUEAKrVl3FiBEHkZCQAgAoVkwPq1a1ZWFDlE0aedhIeHg4vv/+e5QvX17tdZcuXQonJycYGBjAzc0Np0+fznL5xMRETJgwAQ4ODtDX10e5cuWwdu3anEYnIso3YmIS0b37Tgwe/LeysHF1tcXVq4PQtWtVidMRFRzZLm7evn2LHj16wNraGvb29li0aBEUCgUmTZqEsmXL4sKFC2oXGQEBARg5ciQmTJiAa9euoX79+mjZsiVCQkIyXcfb2xtHjx7FmjVrcP/+fWzevBkuLi5q7TdXnZkgdQIiKoCuXQuDm9tKbNlyW9k2bNjXOHeuPypUsJQwGVHBIxPZvMRp6NCh2LdvH3x8fHDw4EHcu3cPzZs3R0JCAiZPnoyGDRuqvfPatWujZs2aWLZsmbKtUqVK6NChA2bOnJlu+YMHD6Jr164ICgpC8eLF1d4fAMTExMDMzAzR0dEwNTXN0TaytMoRiHma+n373UD59prfBxEVKo8eRaFKlaVISpIDAMzM9LFmTTt07lxZ4mRE+Yc679/Z7rn5559/4O/vjzlz5mDv3r0QQsDZ2RnHjh3LUWGTlJSEK1euwMvLS6Xdy8sL586dy3CdvXv3wt3dHbNmzULJkiXh7OyMMWPGID4+PtP9JCYmIiYmRuUrV8m0P3xftnXu7ouICoXy5YujZ89qAICvv7bH1auDWdgQfYFsDyh+8eIFKldO/WMrW7YsDAwMMGDAgBzvOCIiAnK5HDY2qg93s7GxQXh4eIbrBAUF4cyZMzAwMMCuXbsQERGBoUOHIioqKtNTYjNnzsTUqVNznDPHDK0BrRw9uouIiqBFi1qifPni8POrCz097c+vQESZynbPjUKhgK6urnJaW1sbxsZffpO6T28XLoTI9BbiCoUCMpkMGzduRK1atdCqVSvMmzcP69aty7T3Zvz48YiOjlZ+hYaGfnFmIqKcEkJg4cILCAi4rdJuZKSLceP+x8KGSAOy3bUghECfPn2gr68PAEhISICvr2+6Amfnzp3Z2p6VlRW0tbXT9dK8evUqXW9OGjs7O5QsWRJmZmbKtkqVKkEIgWfPnqFChQrp1tHX11dmJiKSUlRUPPr124M9e+6jWDE91Kxpx8HCRLkg2z03vXv3RokSJWBmZgYzMzN8++23sLe3V06nfWWXnp4e3NzcEBgYqNIeGBiofHbVp+rVq4cXL17g3bsPtyF/8OABtLS0UKpUqWzvm4gor1248AyuriuwZ899AKl3Hz506LHEqYgKp2z33Pj7+2t8535+fujZsyfc3d1Rt25drFy5EiEhIco7HY8fPx7Pnz/H+vXrAQDdu3fHtGnT0LdvX0ydOhURERH44Ycf0K9fPxgaGmo8HxHRl1IoBObOPYeffjqGlJTUu7tbWhrizz87oHVr3pSPKDdIOuLVx8cHkZGR+OWXXxAWFoaqVati//79cHBwAACEhYWp3POmWLFiCAwMxPfffw93d3dYWlrC29sb06dPl+olEBFlKiIiDr1778b+/Q+Vbf/7Xxls3twZpUrlwq0oiAiAGve5KSxy/T43q8sB0UGpV0sNfaX57RNRgXD69FN067YDz5/HAgBkMmD8+P9h6lRP6Oho5ObwREWKOu/fvFaZiEjDEhJS0LXrDrx4kVrYWFsbYcOGTvDyKidxMqKigR8fiIg0zMBAB+vWtYdMBjRq5Ijr131Z2BDlIfbcEBFpgEIhoKX14R5dzZqVw5EjvdCwoQO0tfk5kigv5egv7q+//kK9evVgb2+Pp09Tn6O0YMEC7NmzR6PhiIjyO7lcgalTT+Cbb7bh0yGMjRs7sbAhkoDaf3XLli2Dn58fWrVqhbdv30IuT33Qm7m5ORYsWKDpfERE+VZ4+Dt4eW3AlCknsXPnPfzxx0WpIxERclDc/PHHH1i1ahUmTJgAbe0Ptwl3d3fHrVu3NBqOiCi/OnIkCNWrL8exY8EAAC0tGRISUiRORURADsbcBAcHw9XVNV27vr4+3r9/r5FQRET5VUqKAlOmnMCMGaeRdhbK3t4Emzd3RoMGDtKGIyIAOShunJyccP36deWN9tIcOHBA+dRwIqLC6PnzGHTvvhOnTj1VtrVsWR5//tkB1tZf/iBhItIMtYubH374AcOGDUNCQgKEELh48SI2b96MmTNnYvXq1bmRkYhIcgcOPESvXrsREREHANDWlmHGjCYYM8ZD5SopIpKe2sVN3759kZKSgrFjxyIuLg7du3dHyZIlsXDhQnTt2jU3MhIRSe7PP28oC5vSpU2xZUsXeHiUljgVEWXkix6/EBERAYVCgRIlSmgyU67i4xeIKCeioxNQs+ZKVKliDX//9rC0NJI6ElGRos77t9pXS02dOhWPHz8GAFhZWRWowoaIKLsiI+NUps3MDHD2bD/s2dOVhQ1RPqd2cbNjxw44OzujTp06WLx4MV6/fp0buYiIJJGUJIef3yG4uCzBs2cxKvNsbYtBJuP4GqL8Tu3i5ubNm7h58yYaN26MefPmoWTJkmjVqhU2bdqEuLi4z2+AiCifCg5+g/r1/TF//gVERMSha9ftSElRSB2LiNSUo/uCV6lSBTNmzEBQUBCOHz8OJycnjBw5Era2tprOR0SUJ3buvAdX1xW4ePE5AEBPTxtdu1aFtjZ7aogKmi9+cKaxsTEMDQ2hp6eH2NhYTWQiIsoziYkpGDPmMBYvvqRsK1fOAgEBXeDmZi9hMiLKqRz13AQHB+PXX39F5cqV4e7ujqtXr2LKlCkIDw/XdD4iolzz6FEUPDzWqhQ23t5VcPXqYBY2RAWY2j03devWxcWLF/HVV1+hb9++yvvcEBEVJDt33kOfPrsRG5sEANDX18bChS0waJAbBw0TFXBqFzeenp5YvXo1qlSpkht5iIjyhEwGZWHj7GyJrVu7oHp1jhskKgzULm5mzJiRGzmIiPJUx46V8P33tRAVFY9ly1rDxERf6khEpCHZKm78/Pwwbdo0GBsbw8/PL8tl582bp5FgRESadPZsCDw8Squccpo/vzm0tGQ8DUVUyGSruLl27RqSk5OV3xMRFRRxccn4/vv9WLv2OtaubYe+fV2V87S1c3RNBRHlc9kqbo4fP57h90RE+dndu6/h7b0Nd+6k3kl92LD98PIqh5Ilc+G5ckSUb6j9saVfv34Z3s/m/fv36Nevn0ZCERF9qXXrrsPdfaWysDEy0sWKFW1Y2BAVAWoXN3/++Sfi4+PTtcfHx2P9+vUaCUVElFPv3iWhd+/d6Nt3D+LjUwAAX31VAleuDELPntUlTkdEeSHbV0vFxMRACAEhBGJjY2FgYKCcJ5fLsX//fj4hnIgkdfPmS/j4bMd//0Uo2wYNqokFC1rA0FBXwmRElJeyXdyYm5tDJku9qsDZ2TndfJlMhqlTp2o0HBFRdh048BCdOm1FQkJqb02xYnpYtaotunatKnEyIspr2S5ujh8/DiEEGjdujB07dqB48eLKeXp6enBwcIC9PW9XTkTScHe3R/HihnjxIhY1athi69YuqFDBUupYRCSBbBc3DRs2BJD6XKkyZcrwvhBElK9YWxtjy5bOCAi4gzlzvGBg8MXPBSaiAipbf/03b95E1apVoaWlhejoaNy6dSvTZatVq6axcEREGRFCYM2aa2jXriJKlDBWttev74D69R0kTEZE+UG2ipsaNWogPDwcJUqUQI0aNSCTySCESLecTCaDXC7XeEgiojTR0QkYMGAftm+/i23b7uLAgR7Q0mJPMhF9kK3iJjg4GNbW1srviYikcOnSc/j4bEdw8FsAwOHDj3HsWDCaNi0rbTAiyleyVdw4ODhk+D0RUV4QQmDRon/xww+BSE5WAADMzQ2wbl17FjZElE6ObuL3zz//KKfHjh0Lc3NzeHh44OnTpxoNR0QUFRWPjh0DMHLkIWVhU6dOKVy/Phjt27tInI6I8iO1i5sZM2bA0NAQAHD+/HksXrwYs2bNgpWVFUaNGqXxgERUdF248AyuriuwZ899ZduYMXVx6lQfODiYSxeMiPI1ta+VDA0NRfny5QEAu3fvRpcuXTBo0CDUq1cPjRo10nQ+Iiqi7t17jfr1/ZGSktpbY2lpiD//7IDWrdPfRJSI6GNq99wUK1YMkZGRAIDDhw+jadOmAAADA4MMnzlFRJQTlSpZo0ePrwAA//tfGVy/7svChoiyRe2em2bNmmHAgAFwdXXFgwcP0Lp1awDAnTt34OjoqOl8RFSELVnSCl99VQIjRtSBjo7an8WIqIhS+3+LJUuWoG7dunj9+jV27NgBS8vU25tfuXIF3bp103hAIir8FAqBGTNOY/v2uyrtxsZ6GD3ag4UNEalF7Z4bc3NzLF68OF07H5pJRDnx6tV79Oy5C4cPP4apqT5cXW1Rrlzxz69IRJSJHD185e3bt1izZg3u3bsHmUyGSpUqoX///jAzM9N0PiIqxE6ceILu3XcgLOwdACA2NhHHjz9hcUNEX0Ttvt7Lly+jXLlymD9/PqKiohAREYH58+ejXLlyuHr1am5kJKJCRi5X4JdfTqJJk/XKwsbGxhiBgT0xYEBNidMRUUGnds/NqFGj0K5dO6xatQo6Oqmrp6SkYMCAARg5ciROnTql8ZBEVHiEh79Djx47cezYh0e5NG1aFhs2dISNTTEJkxFRYaF2cXP58mWVwgYAdHR0MHbsWLi7u2s0HBEVLkeOBKFHj5149eo9AEBLS4apUxth/Pj/QVubg4aJSDPULm5MTU0REhICFxfV256HhobCxMREY8GIqHB5/z5JpbCxtzfBpk2d0LCho7TBiKjQUfujko+PD/r374+AgACEhobi2bNn2LJlCwYMGMBLwYkoU8bGevjzzw4AgBYtyuP69cEsbIgoV6jdczNnzhzIZDL06tULKSkpAABdXV0MGTIEv/32m8YDElHBpVAIaGnJlNMtWpTH8eO90aCBg0o7EZEmyYQQIicrxsXF4fHjxxBCoHz58jAyMtJ0tlwRExMDMzMzREdHw9TUVPM7WF0OiA4CDK2Boa80v32iAiA5WY6JE48hKOgttm7tApmMhQwRfRl13r+zfVoqLi4Ow4YNQ8mSJVGiRAkMGDAAdnZ2qFatWoEpbIgo94WERKNRoz8xa9Y5bN9+F0uXXpI6EhEVMdkubiZPnox169ahdevW6Nq1KwIDAzFkyJDczEZEBcy+fffh6roC586FAgB0dLQgl+eoc5iIKMeyPeZm586dWLNmDbp27QoA+Pbbb1GvXj3I5XJoa2vnWkAiyv+SkuQYP/4I5s27oGxzcDBDQEAX1K5dSsJkRFQUZbu4CQ0NRf369ZXTtWrVgo6ODl68eIHSpUvnSjgiyv+Cg9+ga9cduHjxubKtQwcXrF3bDhYWhhImI6KiKtvFjVwuh56enurKOjrKK6aIqOjZtese+vbdg+joRACAnp425sxphu++q8VBxEQkmWwXN0II9OnTB/r6+sq2hIQE+Pr6wtjYWNm2c+dOzSYkonxr48ZbysKmbFkLbN3aBW5u9hKnIqKiLtvFTe/evdO1ffvttxoNQ0QFy+rV7XDlShhq1SqJlSvbwMzMQOpIRETZL278/f1zMwcRFQCvXr1HiRIfemrNzQ1w4UJ/lChhzNNQRJRvSP6kuqVLl8LJyQkGBgZwc3PD6dOns7Xe2bNnoaOjgxo1auRuQCJCfHwyhgz5G1WqLMXz5zEq82xsirGwIaJ8RdLiJiAgACNHjsSECRNw7do11K9fHy1btkRISEiW60VHR6NXr15o0qRJHiUlKrru349AnTprsHz5FURExKF7952QyxVSxyIiypSkxc28efPQv39/DBgwAJUqVcKCBQtQunRpLFu2LMv1Bg8ejO7du6Nu3bp5lJSoaNq48Sbc3Fbi5s2XAAADAx306lWNz4UionxNsuImKSkJV65cgZeXl0q7l5cXzp07l+l6/v7+ePz4MSZPnpzbEYmKrLi4ZAwYsBfffrsL798nAwAqVbLCpUsD0b9/TZ6GIqJ8Te2ngmtKREQE5HI5bGxsVNptbGwQHh6e4ToPHz7EuHHjcPr0aejoZC96YmIiEhMTldMxMTFZLE1E9+69hrf3dty+/eHBr717V8eSJa1gbKyXxZpERPlDjnpu/vrrL9SrVw/29vZ4+vQpAGDBggXYs2eP2tv69BOgECLDT4VyuRzdu3fH1KlT4ezsnO3tz5w5E2ZmZsov3k2ZKHObNt2Cu/sqZWFjZKSLdevaY926DixsiKjAULu4WbZsGfz8/NCqVSu8ffsWcrkcAGBubo4FCxZkeztWVlbQ1tZO10vz6tWrdL05ABAbG4vLly/ju+++g46ODnR0dPDLL7/gxo0b0NHRwbFjxzLcz/jx4xEdHa38Cg0Nzf6LJSpidHW1EBeXehqqatUSuHx5IHr3riFtKCIiNald3Pzxxx9YtWoVJkyYoPLATHd3d9y6dSvb29HT04ObmxsCAwNV2gMDA+Hh4ZFueVNTU9y6dQvXr19Xfvn6+qJixYq4fv06ateuneF+9PX1YWpqqvJFRBn75psqGDLEHQMGuOLffwegUiVrqSMREalN7TE3wcHBcHV1Tdeur6+P9+/fq7UtPz8/9OzZE+7u7qhbty5WrlyJkJAQ+Pr6AkjtdXn+/DnWr18PLS0tVK1aVWX9EiVKwMDAIF07EX2eEAInTz5Fo0aOKu2LF7fi1VBEVKCpXdw4OTnh+vXrcHBwUGk/cOAAKleurNa2fHx8EBkZiV9++QVhYWGoWrUq9u/fr9x2WFjYZ+95Q0Tqi41NxODBf2Pz5ttYt669yqknFjZEVNDJhBBCnRX8/f3x888/Y+7cuejfvz9Wr16Nx48fY+bMmVi9ejW6du2aW1k1IiYmBmZmZoiOjs6dU1SrywHRQYChNTD01eeXJ8pj166Fwdt7Ox49igKQOmg4KGg4bGyKSZyMiChz6rx/q91z07dvX6SkpGDs2LGIi4tD9+7dUbJkSSxcuDDfFzZERZkQAsuWXcaoUYeQlJR6IYCpqT5WrWrLwoaICpUc3edm4MCBGDhwICIiIqBQKFCiRAlN5yIiDYqOTsCAAfuwfftdZZubmx0CArqgXLniEiYjItK8L7qJn5WVlaZyEFEuuXz5Bby9tyE4+K2ybfjwWpg1qxn09SW7jycRUa7J0YDirG69HhQU9EWBiEhz9uz5D998sw3JyakPujQ3N4C/f3t06OAicTIiotyjdnEzcuRIlenk5GRcu3YNBw8exA8//KCpXESkAXXrloaVlRHCwt6hdu2S2LKlCxwdzaWORUSUq9QubkaMGJFh+5IlS3D58uUvDkREmlOihDE2beqMv/9+gBkzmkBPT/vzKxERFXAaeyp4y5YtsWPHDk1tjojUpFAILFlyEa9fq95Ms1EjR8yZ48XChoiKDI0VN9u3b0fx4rzqgkgKkZFxaNduM7777gB6994NhUKt21cRERUqap+WcnV1VRlQLIRAeHg4Xr9+jaVLl2o0HBF93pkzIejWbQeePYsBABw48AhnzoSgQQOHz6xJRFQ4qV3cdOjQQWVaS0sL1tbWaNSoEVxceAUGUV5RKAR+//0Mfv75OOTy1J4aKysjbNjQkYUNERVpahU3KSkpcHR0RPPmzWFra5tbmYjoM169eo+ePXfh8OHHyraGDR2waVNn2NubSJiMiEh6ao250dHRwZAhQ5CYmJhbeYjoM06ceIIaNZYrCxuZDPj55wY4cqQXCxsiIuTgtFTt2rVx7dq1dE8FJ6Lcd+NGOJo0Wa8cMGxjY4wNGzqhadOyEicjIso/1C5uhg4ditGjR+PZs2dwc3ODsbGxyvxq1appLBwRqapWzQbdu3+FDRtuokkTJ2zY0Am2tnzoJRHRx7Jd3PTr1w8LFiyAj48PAGD48OHKeTKZDEIIyGQyyOVyzackIgCpf2vLlrVGrVr2GDr0a2hra+xuDkREhYZMCJGtG2Joa2sjLCwM8fHxWS6X309XxcTEwMzMDNHR0TA1NdX8DlaXA6KDAENrYOgrzW+fioyUFAWmTj2BmjXt0LFjJanjEBFJSp3372z33KTVQPm9eCEqDJ4/j0H37jtx6tRTmJsbwNXVjs+EIiLKJrX6tLN6GjgRacbBg49Qo8YKnDr1FAAQG5uIM2dCJE5FRFRwqDWg2NnZ+bMFTlRU1BcFIiqqkpPl+Pnn4/j997PKtlKlTLFlS2fUq1dGwmRERAWLWsXN1KlTYWZmlltZiIqs0NBodO26A+fOhSrbWreugD//7ABLSyMJkxERFTxqFTddu3ZFiRIlcisLUZG0b9999OmzB1FRqYP1dXS08NtvTTBqVF1oafFUMBGRurJd3HC8DZHmxcYmol+/vcrCxsHBDFu2dEGdOqUkTkZEVHBle0BxNq8YJyI1mJjoY9269gCADh1ccO3aYBY2RERfKNs9NwqFIjdzEBUZcrlC5eZ7rVs74/TpvqhXrzR7SImINIC3NyXKI4mJKRg+/AB69NiZrif0f/8rw8KGiEhD1H62FBGp7/HjKPj4bMeVK2EAgEaNHOHr6y5xKiKiwonFDVEu27btDgYM2IeYmEQAgL6+NnR02GlKRJRbWNwQ5ZKEhBT4+R3CsmWXlW0VKhTH1q3foEYNWwmTEREVbixuiHLBgweR8Pbehhs3Xirbunf/CsuXt4aJib6EyYiICj8WN0QatmnTLQwe/DfevUsCABgY6GDx4pbo18+Vg4aJiPIAixsiDRJCYNu2u8rCxsXFCtu2fYOqVXlnbyKivMLihkiDZDIZ1qxph6tXw+Dp6YglS1rB2FhP6lhEREUKixuiLxQWFgs7OxPldPHihrhyZRCsrPjASyIiKfB6VKIcev8+Cb1770b16ssRFharMo+FDRGRdFjcEOXArVsv4e6+CuvX38Dr13Ho3n0nFAo+f42IKD9gcUOkBiEEVq++ilq1VuO//yIAAMWK6WHgwJrQ0uKVUERE+QHH3BBlU2xsIgYP/hubN99WtlWvboOtW7+Bs7OlhMmIiOhjLG6IsuH69XB4e2/Dw4dRyrYhQ9wxb15zGBjwz4iIKD/h/8pEn7FmzVUMG7YfiYlyAICpqT5WrWoLb+8qEicjIqKMsLgh+gxjYz1lYePmZoeAgC4oV664xKmIiCgzLG6IPqNr16o4fjwY+vo6mD27GfT1+WdDRJSf8X9poo8IIXD0aDCaNi2r0r5sWRteDUVEVEDwUnCi//fmTTw6ddqKZs3+wsaNN1XmsbAhIio4WNwQAfj332dwdV2B3bv/AwD4+v6DyMg4iVMREVFOsLihIk0Igblzz+F///PH06fRAFKfDbV5c2dYWvIRCkREBRHH3FCRFRkZhz599uDvvx8o2+rVK43NmzujdGkzCZMREdGXYHGjScnvgeggqVNQNpw9G4KuXXfg2bMYZdu4cfXwyy+e0NXVljAZERF9KRY3mvT47w/fJ0RlvhxJauvWO+jefQfk8tQHXVpZGeGvvzqiRYvyEicjIiJN4JgbTUp+9+H70o0ki0FZa9DAAVZWRsrvr18fzMKGiKgQYc9NbqnYVeoElAlb22LYuLETTpx4gsmTG0FHhzU+EVFhwv/VqVCTyxWYN+98usu6mzQpi2nTGrOwISIqhPg/OxVa4eHv0Lz5BowefRh9++6BEELqSERElAdY3FChdPRoEGrUWI6jR4MBAP/88xD//vtc4lRERJQXWNxQoSKXKzBp0nE0a/YXXr58DwCwsyuGY8d6oU6dUhKnIyKivMABxZqkSJY6QZH24kUsunffgZMnnyrbmjcvh/XrO6JECWMJkxERUV5icaNJR4ZInaDIOnjwEXr23IWIiNSBw9raMkyf3hhjx9bjQy+JiIoYyU9LLV26FE5OTjAwMICbmxtOnz6d6bI7d+5Es2bNYG1tDVNTU9StWxeHDh3Kw7SfYWj14XvratLlKGIuXXqOli03KgubUqVMceJEH4wb9z8WNkRERZCkxU1AQABGjhyJCRMm4Nq1a6hfvz5atmyJkJCQDJc/deoUmjVrhv379+PKlSvw9PRE27Ztce3atTxOnpmP3khtv5YuRhHj7m6Pbt2qAgDatHHG9euD8b//lZE4FRERSUUmJLw+tnbt2qhZsyaWLVumbKtUqRI6dOiAmTNnZmsbVapUgY+PDyZNmpSt5WNiYmBmZobo6GiYmprmKHem5v5/cWNWFhjwWLPbpizFxCRi8+ZbGDTIDTIZe2uIiAobdd6/Jeu5SUpKwpUrV+Dl5aXS7uXlhXPnzmVrGwqFArGxsShevHhuRFTP61tSJygSkpPl+OGHw9i7975Ku6mpPgYPdmdhQ0RE0g0ojoiIgFwuh42NjUq7jY0NwsPDs7WNuXPn4v379/D29s50mcTERCQmJiqnY2JiMl32i4Qc/fB9/Ovc2UcR9+TJW3Ttuh3//vsca9Zcw7Vrg+HgYC51LCIiymckH1D86SdtIUS2Pn1v3rwZU6ZMQUBAAEqUKJHpcjNnzoSZmZnyq3Tp0l+cOWMfnd2rOyWX9lF07d79H1xdVyhvxPfuXRIuXuRN+YiIKD3JihsrKytoa2un66V59epVut6cTwUEBKB///7YunUrmjZtmuWy48ePR3R0tPIrNDT0i7N/lglvFqcpiYkpGDnyIDp2DMDbtwkAgLJlLXDuXH98800VidMREVF+JFlxo6enBzc3NwQGBqq0BwYGwsPDI9P1Nm/ejD59+mDTpk1o3br1Z/ejr68PU1NTlS8qGB4/jkK9emuxcOG/yrYuXSrj6tVBcHe3lzAZERHlZ5LexM/Pzw89e/aEu7s76tati5UrVyIkJAS+vr4AUntdnj9/jvXr1wNILWx69eqFhQsXok6dOspeH0NDQ5iZmUn2Okjztm27gwED9iEmJnW8lL6+NubPbw5fXw4aJiKirEla3Pj4+CAyMhK//PILwsLCULVqVezfvx8ODg4AgLCwMJV73qxYsQIpKSkYNmwYhg0bpmzv3bs31q1bl9fxKZe8eROPwYP/VhY2FSoUx9at36BGDVuJkxERUUEg6X1upJBr97m5Mh844Zf6fZsAoGLmV3DR5+3Z8x86dAhAt25VsWJFG5iY6EsdiYiIJKTO+zefLUX5QkqKAjo6H4aAtW/vgvPn+6N27ZI8DUVERGqR/FJwKtri45MxaNA+9Oq1C592ItapU4qFDRERqY09NySZe/dew9t7O27ffgUA8PR0xMCBbhKnIiKigo7FDUli/fobGDLkH8TFJQMAjIx0YWDAX0ciIvpyfDehPPX+fRK+++4A1q27rmyrUsUaW7d+g8qVraULRkREhQaLG8ozt2+/grf3Nty7F6Fs69/fFYsWtYSRka6EyYiIqDBhcUO5TgiBtWuv4fvvDyA+PgUAYGysixUr2qBHj2oSpyMiosKGxQ3lid277ysLm+rVbbB16zdwdraUOBURERVGvBSccp1MJsO6de1RurQpfH3dcOHCABY2RESUa9hzQxonhMCLF7EoWfLDHSQtLY1w/bovihc3lDAZEREVBey5IY2KiUlE16474Oa2EuHh71TmsbAhIqK8wOKGNObKlReoWXMFtm69g5cv3+Pbb3emu+swERFRbmNxQ19MCIE//vgXHh5r8fjxGwCAmZk+hg79mo9PICKiPMcxN/RF3ryJR//+e7Fr13/Ktlq1SmLLls5wcrKQMBkRERVVLG4oxy5efA4fn+148uStss3Prw5mzmwKPT1t6YIREVGRxuKGcmTp0ksYMeIgUlIUAAALCwP8+WcHtG1bUeJkRERU1LG4oRwxM9NXFjYeHqWxeXNnlCljJnEqIiIiFjeUQz16VMPJk09RvLghpk3zhK4uT0MREVH+wOKGPkuhEAgMfIzmzcurtK9Y0YZXQxERUb7DS8EpS69fv0ebNpvQosVGBATcVpnHwoaIiPIjFjeUqVOnnqJGjRU4cOARAGDw4L/x9m2CxKmIiIiyxuKG0pHLFZg+/RQ8Pf/EixexAAAbG2Ns3+4Nc3MDidMRERFljWNuSMXLl+/w7be7cORIkLKtcWMnbNzYCba2xSRMRkRElD0sbkjp2LFg9OixU/nASy0tGSZPbogJE+pDW5udfEREVDCwuCEAwF9/3UDv3ruR9pxLO7ti2LSpMxo1cpQ0FxERkbr4cZwAAE2bloW1tTEAwMurHK5f92VhQ0REBRJ7bggAYGdngg0bOuLSpRcYN+5/0NLiZd5ERFQwseemCEpJUeC3387gzZt4lfZmzcrhp5/qs7AhIqICjT03RcyzZzHo1m0HzpwJwb//PsfOnd68GR8RERUq7LkpQv755wFq1FiOM2dCAAB///0A166FS5yKiIhIs1jcFAHJyXL88MNhtGmzGZGRqaeiypQxw+nTfVGzpp3E6YiIiDSLp6UKuadP36Jr1x24cOGZsq19+4pYu7Y9ihc3lDAZERFR7mBxU4jt2fMf+vbdgzdvUp8Hpaurhdmzm2H48NocZ0NERIUWi5tC6ty5UHToEKCcdnIyR0BAF3z9dUkJUxEREeU+jrkppOrWLQVv7yoAgM6dK+Hq1cEsbIiIqEhgz00hJZPJsHJlG7RoUQ59+tTgaSgiIioy2HNTCCQkpOC77/bjn38eqLSbmRmgb19XFjZERFSksLgp4B4+jISHxxosWXIJvXvvxrNnMVJHIiIikhSLmwJsy5bbqFlzpfJGfO/fJ+Pq1TCJUxEREUmLY24KoPj4ZIwceRArV15VtlWsaImtW79BtWo2EiYjIiKSHoubAua//yLg7b0Nt269Urb17FkNS5e2RrFiehImIyIiyh9Y3BQgf/11A0OG/IP375MBAEZGuliypBX69KkhbTAiIqJ8hMVNAREREYfvvz+gLGyqVLHG1q3foHJla4mTERER5S8cUFxAWFkZYe3a9gCA/v1dcfHiQBY2REREGWDPTT4lhEBKigK6utrKtk6dKuHixQG80zAREVEWWNzkQ+/eJcHX929oacnw558dVG7Cx8KGKO+lfthIgVwulzoKUaGmq6sLbW3tzy/4GSxu8pkbN8Lh7b0dDx5EAgA8PR3Rt6+rxKmIiq6kpCSEhYUhLi5O6ihEhZ5MJkOpUqVQrFixL9oOi5t8QgiBlSuvYMSIg0hMTP10aGKiBxMTfYmTERVdCoUCwcHB0NbWhr29PfT09Pg4E6JcIoTA69ev8ezZM1SoUOGLenBY3OQDMTGJGDhwH7ZuvaNsq1nTDgEBXVC+fHEJkxEVbUlJSVAoFChdujSMjIykjkNU6FlbW+PJkydITk5mcVOQXb0aBm/vbXj8+I2y7fvva2H27GbQ1+ePhyg/0NLihaVEeUFTPaN895SIEAJLllzC6NGHkZSUehrKzEwfa9e2R6dOlSROR0REVHCxuJGIEMD+/Q+Vhc3XX9sjIKALnJwsJE5GRERUsLGvVSJpl3mXLGkCP786OHOmHwsbIiKJRUZGokSJEnjy5InUUQqdxYsXo127dnmyLxY3eUQIgdDQaJU2a2tj3L49FHPnNoee3pdf109EBAB9+vSBTCaDTCaDjo4OypQpgyFDhuDNmzfplj137hxatWoFCwsLGBgY4KuvvsLcuXMzvKfP8ePH0apVK1haWsLIyAiVK1fG6NGj8fz587x4WXli5syZaNu2LRwdHaWOkmtOnjwJNzc3GBgYoGzZsli+fPln1zl69Cg8PDxgYmICOzs7/Pjjj0hJSVFZ5tChQ6hTpw5MTExgbW2Nzp07Izg4WDl/4MCBuHTpEs6cOaPx1/QpFjd5ICoqHu3bb0Ht2qvx6tV7lXnm5gYSpSKiwqxFixYICwvDkydPsHr1auzbtw9Dhw5VWWbXrl1o2LAhSpUqhePHj+O///7DiBEj8Ouvv6Jr164QQiiXXbFiBZo2bQpbW1vs2LEDd+/exfLlyxEdHY25c+fm2etKSkrKtW3Hx8djzZo1GDBgwBdtJzczfqng4GC0atUK9evXx7Vr1/DTTz9h+PDh2LFjR6br3Lx5E61atUKLFi1w7do1bNmyBXv37sW4ceOUywQFBaF9+/Zo3Lgxrl+/jkOHDiEiIgKdOnVSLqOvr4/u3bvjjz/+yNXXCAAQRUx0dLQAIKKjozW74cvzhJiD1K//ApTNZ8+GiNKl5wlgigCmiBYtNgiFQqHZfRNRroiPjxd3794V8fHxUkdRS+/evUX79u1V2vz8/ETx4sWV0+/evROWlpaiU6dO6dbfu3evACC2bNkihBAiNDRU6OnpiZEjR2a4vzdv3mSa5c2bN2LgwIGiRIkSQl9fX1SpUkXs27dPCCHE5MmTRfXq1VWWnz9/vnBwcEj3WmbMmCHs7OyEg4ODGDdunKhdu3a6fX311Vdi0qRJyum1a9cKFxcXoa+vLypWrCiWLFmSaU4hhNixY4ewsrJSaUtJSRH9+vUTjo6OwsDAQDg7O4sFCxaoLJNRRiGEePbsmfD29hbm5uaiePHiol27diI4OFi53sWLF0XTpk2FpaWlMDU1FQ0aNBBXrlzJMuOXGjt2rHBxcVFpGzx4sKhTp06m64wfP164u7urtO3atUsYGBiImJgYIYQQ27ZtEzo6OkIulyuX2bt3r5DJZCIpKUnZduLECaGnpyfi4uIy3FdWf3PqvH9zQHEuUSgE5sw5h59+Ogq5PPXTj6WlIb7/vhZvAkZUkG1wB96H5/1+jW2Bby/naNWgoCAcPHgQurq6yrbDhw8jMjISY8aMSbd827Zt4ezsjM2bN8PHxwfbtm1DUlISxo4dm+H2zc3NM2xXKBRo2bIlYmNjsWHDBpQrVw53795V+/4lR48ehampKQIDA5W9Sb/99hseP36McuXKAQDu3LmDW7duYfv27QCAVatWYfLkyVi8eDFcXV1x7do1DBw4EMbGxujdu3eG+zl16hTc3d3TvYZSpUph69atsLKywrlz5zBo0CDY2dnB29s704xxcXHw9PRE/fr1cerUKejo6GD69Olo0aIFbt68CT09PcTGxqJ3795YtGgRAGDu3Llo1aoVHj58CBMTkwwzbty4EYMHD87yeK1YsQI9evTIcN758+fh5eWl0ta8eXOsWbMGycnJKr8jaRITE2FgoHqWwdDQEAkJCbhy5QoaNWoEd3d3aGtrw9/fH3369MG7d+/w119/wcvLS2Wb7u7uSE5OxsWLF9GwYcMsX8eXkLy4Wbp0KWbPno2wsDBUqVIFCxYsQP369TNd/uTJk/Dz88OdO3dgb2+PsWPHwtfXNw8Tf97rqBT0brMJBw48UrbVr18GmzZ1RqlSphImI6Iv9j4ceJf/x5j8/fffKFasGORyORISEgAA8+bNU85/8OABAKBSpYxvPeHi4qJc5uHDhzA1NYWdnZ1aGY4cOYKLFy/i3r17cHZ2BgCULVtW7ddibGyM1atXQ09PT9lWrVo1bNq0CT///DOA1Df9r7/+WrmfadOmYe7cucrTIk5OTrh79y5WrFiRaXHz5MkT2Nvbq7Tp6upi6tSpymknJyecO3cOW7duVSluPs24du1aaGlpYfXq1coPtP7+/jA3N8eJEyfg5eWFxo0bq+xrxYoVsLCwwMmTJ9GmTZsMM7Zr1w61a9fO8njZ2NhkOi88PDzdfBsbG6SkpCAiIiLDn3Hz5s2xYMECbN68Gd7e3ggPD8f06dMBAGFhYQAAR0dHHD58GN988w0GDx4MuVyOunXrYv/+/SrbMjY2hrm5OZ48eVJ4i5uAgACMHDkSS5cuRb169bBixQq0bNkSd+/eRZkyZdItn3aucODAgdiwYQPOnj2LoUOHKgcu5QenHjug26xgvHiVOtBKJgMmTKiPyZMbQUeHQ5yICjxj2wKxX09PTyxbtgxxcXFYvXo1Hjx4gO+//z7dcuKjcTWftqe9KX/8vTquX7+OUqVKKQuOnPrqq69UChsA6NGjB9auXYuff/4ZQghs3rwZI0eOBAC8fv0aoaGh6N+/PwYOHKhcJyUlBWZmZpnuJz4+Pl0PBQAsX74cq1evxtOnTxEfH4+kpCTUqFEjy4xXrlzBo0eP0vXAJCQk4PHjxwCAV69eYdKkSTh27BhevnwJuVyOuLg4hISEZJrRxMQk016d7Pr0Z5n2O5DZz9jLywuzZ8+Gr68vevbsCX19ffz88884c+aMshcuPDwcAwYMQO/evdGtWzfExsZi0qRJ6NKlCwIDA1W2bWhomOvPapO0uJk3bx769++vHLy1YMECHDp0CMuWLcPMmTPTLb98+XKUKVMGCxYsAJD6iePy5cuYM2dOvihu5p6oi7H/NINCpBY2JUoYY8OGjmjWrJzEyYhIY3J4aiivGRsbo3z58gCARYsWwdPTE1OnTsW0adMAQFlw3Lt3Dx4eHunW/++//1C5cmXlstHR0QgLC1Or98bQ0DDL+VpaWumKq+Tk5Axfy6e6d++OcePG4erVq4iPj0doaCi6du0KIPVUEpB6aurTXo6sTolZWVmlu6Js69atGDVqFObOnYu6devCxMQEs2fPxr///ptlRoVCATc3N2zcuDHdfqytrQGkXtX2+vVrLFiwAA4ODtDX10fdunWzHJD8paelbG1tER6uelr11atX0NHRgaWlZabb9PPzw6hRoxAWFgYLCws8efIE48ePh5OTEwBgyZIlMDU1xaxZs5TrbNiwAaVLl8a///6LOnXqKNujoqKUxyC3SFbcJCUl4cqVKyqjrYHUCvHcuXMZrpPTc4WJiYnK6ZiYGA2kz5iVcRwUIrV3xtPTERs3doKd3ZdV2EREmjB58mS0bNkSQ4YMgb29Pby8vFC8eHHMnTs3XXGzd+9ePHz4UFkIdenSBePGjcOsWbMwf/78dNt++/ZthuNuqlWrhmfPnuHBgwcZ9t5YW1sjPDxcpWfo+vXr2Xo9pUqVQoMGDbBx40bEx8ejadOmytMtNjY2KFmyJIKCgjJ9k8+Iq6srNmzYoNJ2+vRpeHh4qFxpltbzkpWaNWsiICAAJUqUgKlpxsMRTp8+jaVLl6JVq1YAgNDQUERERGS53S89LVW3bl3s27dPpe3w4cNwd3fP8D30YzKZTHnabvPmzShdujRq1qwJAIiLi0tXOKZNpxWbQOqxS0hIgKura5b7+mKfHXKcS54/fy4AiLNnz6q0//rrr8LZ2TnDdSpUqCB+/fVXlbazZ88KAOLFixcZrjN58mQBIN1Xbl0t1a9WOzHlu8UiJUX++XWIKF8rTFdLCSGEm5ubGDZsmHJ627ZtQltbWwwcOFDcuHFDBAcHi9WrVwsLCwvRpUsXlSs7lyxZImQymejXr584ceKEePLkiThz5owYNGiQ8PPzyzRLo0aNRNWqVcXhw4dFUFCQ2L9/vzhw4IAQQoi7d+8KmUwmfvvtN/Ho0SOxePFiYWFhkeHVUhlZuXKlsLe3F1ZWVuKvv/5Smbdq1SphaGgoFixYIO7fvy9u3rwp1q5dK+bOnZtp1ps3bwodHR0RFRWlbFuwYIEwNTUVBw8eFPfv3xcTJ04UpqamKld5ZZTx/fv3okKFCqJRo0bi1KlTIigoSJw4cUIMHz5chIaGCiGEqFGjhmjWrJm4e/euuHDhgqhfv74wNDQU8+fPzzTjlwoKChJGRkZi1KhR4u7du2LNmjVCV1dXbN++XbnMzp07RcWKFVXWmzVrlrh586a4ffu2+OWXX4Surq7YtWuXcv7Ro0eFTCYTU6dOFQ8ePBBXrlwRzZs3Fw4ODipXRvn7+4uyZctmmk9TV0tJXtycO3dOpX369OnpDmqaChUqiBkzZqi0nTlzRgAQYWFhGa6TkJAgoqOjlV+hoaG5U9xEPRTiwS6huL9TiJhnmt02EUmisBU3GzduFHp6eiIkJETZdurUKdGiRQthZmYm9PT0ROXKlcWcOXNESkpKuvUDAwNF8+bNhYWFhTAwMBAuLi5izJgxmX64FEKIyMhI0bdvX2FpaSkMDAxE1apVxd9//62cv2zZMlG6dGlhbGwsevXqJX799ddsFzdv3rwR+vr6wsjISMTGxmb4emvUqCH09PSEhYWFaNCggdi5c2emWYUQok6dOmL58uXK6YSEBNGnTx9hZmYmzM3NxZAhQ8S4ceM+W9wIIURYWJjo1auXsLKyEvr6+qJs2bJi4MCByvefq1evCnd3d6Gvry8qVKggtm3bJhwcHHK1uBEi9XJsV1dXoaenJxwdHcWyZctU5vv7+4tP+z48PT2FmZmZMDAwELVr1xb79+9Pt93NmzcLV1dXYWxsLKytrUW7du3EvXv3VJbx8vISM2fOzDSbpoobmRCZjCbLZUlJSTAyMsK2bdvQsWNHZfuIESNw/fp1nDx5Mt06DRo0gKurKxYuXKhs27VrF7y9vREXF/fZLjUg9bSUmZkZoqOjM+0qJCICUgd/BgcHw8nJKcOBplT47N+/H2PGjMHt27f5NHgNu337Npo0aYIHDx5kOrA7q785dd6/JfvJ6enpwc3NDYGBgSrtgYGBGQ5uA1LPFX66fHbPFRIREX1Oq1atMHjw4EL1SIn84sWLF1i/fn2WV6xpiqRXS/n5+aFnz55wd3dH3bp1sXLlSoSEhCjvWzN+/Hg8f/4c69evBwD4+vpi8eLF8PPzw8CBA3H+/HmsWbMGmzdvlvJlEBFRITJixAipIxRKn14QlJskLW58fHwQGRmJX375BWFhYahatSr2798PBwcHAKk3B/r4en8nJyfs378fo0aNwpIlS2Bvb49Fixbli8vAiYiIKH+QbMyNVDjmhoiyi2NuiPJWgR9zQ0RUUBSxz4BEktHU3xqLGyKiTKRdqJDbt4onolRpd2dW9+Gqn5L8wZlERPmVtrY2zM3N8erVKwCAkZFRjp6xRESfp1Ao8Pr1axgZGUFH58vKExY3RERZsLVNfWBlWoFDRLlHS0sLZcqU+eIPESxuiIiyIJPJYGdnhxIlSmT4UEci0hw9PT2N3DyRxQ0RUTZoa2t/8TgAIsobHFBMREREhQqLGyIiIipUWNwQERFRoVLkxtyk3SAoJiZG4iRERESUXWnv29m50V+RK25iY2MBAKVLl5Y4CREREakrNjb2s08WL3LPllIoFHjx4gVMTEw0fjOumJgYlC5dGqGhoXxuVS7icc4bPM55g8c57/BY543cOs5CCMTGxsLe3v6zl4sXuZ4bLS0tlCpVKlf3YWpqyj+cPMDjnDd4nPMGj3Pe4bHOG7lxnD/XY5OGA4qJiIioUGFxQ0RERIUKixsN0tfXx+TJk6Gvry91lEKNxzlv8DjnDR7nvMNjnTfyw3EucgOKiYiIqHBjzw0REREVKixuiIiIqFBhcUNERESFCosbIiIiKlRY3Khp6dKlcHJygoGBAdzc3HD69Okslz958iTc3NxgYGCAsmXLYvny5XmUtGBT5zjv3LkTzZo1g7W1NUxNTVG3bl0cOnQoD9MWXOr+Pqc5e/YsdHR0UKNGjdwNWEioe5wTExMxYcIEODg4QF9fH+XKlcPatWvzKG3Bpe5x3rhxI6pXrw4jIyPY2dmhb9++iIyMzKO0BdOpU6fQtm1b2NvbQyaTYffu3Z9dR5L3QUHZtmXLFqGrqytWrVol7t69K0aMGCGMjY3F06dPM1w+KChIGBkZiREjRoi7d++KVatWCV1dXbF9+/Y8Tl6wqHucR4wYIX7//Xdx8eJF8eDBAzF+/Hihq6srrl69msfJCxZ1j3Oat2/firJlywovLy9RvXr1vAlbgOXkOLdr107Url1bBAYGiuDgYPHvv/+Ks2fP5mHqgkfd43z69GmhpaUlFi5cKIKCgsTp06dFlSpVRIcOHfI4ecGyf/9+MWHCBLFjxw4BQOzatSvL5aV6H2Rxo4ZatWoJX19flTYXFxcxbty4DJcfO3ascHFxUWkbPHiwqFOnTq5lLAzUPc4ZqVy5spg6daqmoxUqOT3OPj4+YuLEiWLy5MksbrJB3eN84MABYWZmJiIjI/MiXqGh7nGePXu2KFu2rErbokWLRKlSpXItY2GTneJGqvdBnpbKpqSkJFy5cgVeXl4q7V5eXjh37lyG65w/fz7d8s2bN8fly5eRnJyca1kLspwc508pFArExsaiePHiuRGxUMjpcfb398fjx48xefLk3I5YKOTkOO/duxfu7u6YNWsWSpYsCWdnZ4wZMwbx8fF5EblAyslx9vDwwLNnz7B//34IIfDy5Uts374drVu3zovIRYZU74NF7sGZORUREQG5XA4bGxuVdhsbG4SHh2e4Tnh4eIbLp6SkICIiAnZ2drmWt6DKyXH+1Ny5c/H+/Xt4e3vnRsRCISfH+eHDhxg3bhxOnz4NHR3+15EdOTnOQUFBOHPmDAwMDLBr1y5ERERg6NChiIqK4ribTOTkOHt4eGDjxo3w8fFBQkICUlJS0K5dO/zxxx95EbnIkOp9kD03apLJZCrTQoh0bZ9bPqN2UqXucU6zefNmTJkyBQEBAShRokRuxSs0snuc5XI5unfvjqlTp8LZ2Tmv4hUa6vw+KxQKyGQybNy4EbVq1UKrVq0wb948rFu3jr03n6HOcb579y6GDx+OSZMm4cqVKzh48CCCg4Ph6+ubF1GLFCneB/nxK5usrKygra2d7lPAq1ev0lWlaWxtbTNcXkdHB5aWlrmWtSDLyXFOExAQgP79+2Pbtm1o2rRpbsYs8NQ9zrGxsbh8+TKuXbuG7777DkDqm7AQAjo6Ojh8+DAaN26cJ9kLkpz8PtvZ2aFkyZIwMzNTtlWqVAlCCDx79gwVKlTI1cwFUU6O88yZM1GvXj388MMPAIBq1arB2NgY9evXx/Tp09mzriFSvQ+y5yab9PT04ObmhsDAQJX2wMBAeHh4ZLhO3bp10y1/+PBhuLu7Q1dXN9eyFmQ5Oc5Aao9Nnz59sGnTJp4zzwZ1j7OpqSlu3bqF69evK798fX1RsWJFXL9+HbVr186r6AVKTn6f69WrhxcvXuDdu3fKtgcPHkBLSwulSpXK1bwFVU6Oc1xcHLS0VN8CtbW1AXzoWaAvJ9n7YK4OVy5k0i41XLNmjbh7964YOXKkMDY2Fk+ePBFCCDFu3DjRs2dP5fJpl8CNGjVK3L17V6xZs4aXgmeDusd506ZNQkdHRyxZskSEhYUpv96+fSvVSygQ1D3On+LVUtmj7nGOjY0VpUqVEl26dBF37twRJ0+eFBUqVBADBgyQ6iUUCOoeZ39/f6GjoyOWLl0qHj9+LM6cOSPc3d1FrVq1pHoJBUJsbKy4du2auHbtmgAg5s2bJ65du6a85D6/vA+yuFHTkiVLhIODg9DT0xM1a9YUJ0+eVM7r3bu3aNiwocryJ06cEK6urkJPT084OjqKZcuW5XHigkmd49ywYUMBIN1X79698z54AaPu7/PHWNxkn7rH+d69e6Jp06bC0NBQlCpVSvj5+Ym4uLg8Tl3wqHucFy1aJCpXriwMDQ2FnZ2d6NGjh3j27Fkepy5Yjh8/nuX/t/nlfVAmBPvfiIiIqPDgmBsiIiIqVFjcEBERUaHC4oaIiIgKFRY3REREVKiwuCEiIqJChcUNERERFSosboiIiKhQYXFDRCrWrVsHc3NzqWPkmKOjIxYsWJDlMlOmTEGNGjXyJA8R5T0WN0SFUJ8+fSCTydJ9PXr0SOpoWLdunUomOzs7eHt7Izg4WCPbv3TpEgYNGqSclslk2L17t8oyY8aMwdGjRzWyv8x8+jptbGzQtm1b3LlzR+3tFORik0gKLG6ICqkWLVogLCxM5cvJyUnqWABSH8QZFhaGFy9eYNOmTbh+/TratWsHuVz+xdu2traGkZFRlssUK1YsV59InObj1/nPP//g/fv3aN26NZKSknJ930RFGYsbokJKX18ftra2Kl/a2tqYN28evvrqKxgbG6N06dIYOnSoyhOoP3Xjxg14enrCxMQEpqamcHNzw+XLl5Xzz507hwYNGsDQ0BClS5fG8OHD8f79+yyzyWQy2Nraws7ODp6enpg8eTJu376t7FlatmwZypUrBz09PVSsWBF//fWXyvpTpkxBmTJloK+vD3t7ewwfPlw57+PTUo6OjgCAjh07QiaTKac/Pi116NAhGBgY4O3btyr7GD58OBo2bKix1+nu7o5Ro0bh6dOnuH//vnKZrH4eJ06cQN++fREdHa3sAZoyZQoAICkpCWPHjkXJkiVhbGyM2rVr48SJE1nmISoqWNwQFTFaWlpYtGgRbt++jT///BPHjh3D2LFjM12+R48eKFWqFC5duoQrV65g3Lhx0NXVBQDcunULzZs3R6dOnXDz5k0EBATgzJkz+O6779TKZGhoCABITk7Grl27MGLECIwePRq3b9/G4MGD0bdvXxw/fhwAsH37dsyfPx8rVqzAw4cPsXv3bnz11VcZbvfSpUsAAH9/f4SFhSmnP9a0aVOYm5tjx44dyja5XI6tW7eiR48eGnudb9++xaZNmwBAefyArH8eHh4eWLBggbIHKCwsDGPGjAEA9O3bF2fPnsWWLVtw8+ZNfPPNN2jRogUePnyY7UxEhVauP5qTiPJc7969hba2tjA2NlZ+denSJcNlt27dKiwtLZXT/v7+wszMTDltYmIi1q1bl+G6PXv2FIMGDVJpO336tNDS0hLx8fEZrvPp9kNDQ0WdOnVEqVKlRGJiovDw8BADBw5UWeebb74RrVq1EkIIMXfuXOHs7CySkpIy3L6Dg4OYP3++chqA2LVrl8oynz7RfPjw4aJx48bK6UOHDgk9PT0RFRX1Ra8TgDA2NhZGRkbKpye3a9cuw+XTfO7nIYQQjx49EjKZTDx//lylvUmTJmL8+PFZbp+oKNCRtrQiotzi6emJZcuWKaeNjY0BAMePH8eMGTNw9+5dxMTEICUlBQkJCXj//r1ymY/5+flhwIAB+Ouvv9C0aVN88803KFeuHADgypUrePToETZu3KhcXggBhUKB4OBgVKpUKcNs0dHRKFasGIQQiIuLQ82aNbFz507o6enh3r17KgOCAaBevXpYuHAhAOCbb77BggULULZsWbRo0QKtWrVC27ZtoaOT8//OevTogbp16+LFixewt7fHxo0b0apVK1hYWHzR6zQxMcHVq1eRkpKCkydPYvbs2Vi+fLnKMur+PADg6tWrEELA2dlZpT0xMTFPxhIR5XcsbogKKWNjY5QvX16l7enTp2jVqhV8fX0xbdo0FC9eHGfOnEH//v2RnJyc4XamTJmC7t27459//sGBAwcwefJkbNmyBR07doRCocDgwYNVxrykKVOmTKbZ0t70tbS0YGNjk+5NXCaTqUwLIZRtpUuXxv379xEYGIgjR45g6NChmD17Nk6ePKlyukcdtWrVQrly5bBlyxYMGTIEu3btgr+/v3J+Tl+nlpaW8mfg4uKC8PBw+Pj44NSpUwBy9vNIy6OtrY0rV65AW1tbZV6xYsXUeu1EhRGLG6Ii5PLly0hJScHcuXOhpZU65G7r1q2fXc/Z2RnOzs4YNWoUunXrBn9/f3Ts2BE1a9bEnTt30hVRn/Pxm/6nKlWqhDNnzqBXr17KtnPnzqn0jhgaGqJdu3Zo164dhg0bBhcXF9y6dQs1a9ZMtz1dXd1sXYXVvXt3bNy4EaVKlYKWlhZat26tnJfT1/mpUaNGYd68edi1axc6duyYrZ+Hnp5euvyurq6Qy+V49eoV6tev/0WZiAojDigmKkLKlSuHlJQU/PHHHwgKCsJff/2V7jTJx+Lj4/Hdd9/hxIkTePr0Kc6ePYtLly4pC40ff/wR58+fx7Bhw3D9+nU8fPgQe/fuxffff5/jjD/88APWrVuH5cuX4+HDh5g3bx527typHEi7bt06rFmzBrdv31a+BkNDQzg4OGS4PUdHRxw9ehTh4eF48+ZNpvvt0aMHrl69il9//RVdunSBgYGBcp6mXqepqSkGDBiAyZMnQwiRrZ+Ho6Mj3r17h6NHjyIiIgJxcXFwdnZGjx490KtXL+zcuRPBwcG4dOkSfv/9d+zfv1+tTESFkpQDfogod/Tu3Vu0b98+w3nz5s0TdnZ2wtDQUDRv3lysX79eABBv3rwRQqgOYE1MTBRdu3YVpUuXFnp6esLe3l589913KoNoL168KJo1ayaKFSsmjI2NRbVq1cSvv/6aabaMBsh+aunSpaJs2bJCV1dXODs7i/Xr1yvn7dq1S9SuXVuYmpoKY2NjUadOHXHkyBHl/E8HFO/du1eUL19e6OjoCAcHByFE+gHFab7++msBQBw7dizdPE29zqdPnwodHR0REBAghPj8z0MIIXx9fYWlpaUAICZPniyEECIpKUlMmjRJODo6Cl1dXWFrays6duwobt68mWkmoqJCJoQQ0pZXRERERJrD01JERERUqLC4ISIiokKFxQ0REREVKixuiIiIqFBhcUNERESFCosbIiIiKlRY3BAREVGhwuKGiIiIChUWN0RERFSosLghIiKiQoXFDRERERUqLG6IiIioUPk/klmldAr9AoIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4724771121881405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "test_prediction_prob = lr_model.predict_proba(X_train)[:,1]\n",
    "\n",
    "test_predictions = [1 if p >  optimal_threshold else 0 for p in test_prediction_prob]\n",
    "print(\"Optimal Threshold:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81       356\n",
      "           1       0.81      0.84      0.82       364\n",
      "\n",
      "    accuracy                           0.82       720\n",
      "   macro avg       0.82      0.82      0.82       720\n",
      "weighted avg       0.82      0.82      0.82       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_prediction_prob = lr_model.predict_proba(X_val)[:,1]\n",
    "\n",
    "val_predictions = [1 if p > optimal_threshold else 0 for p in val_prediction_prob]\n",
    "\n",
    "print(classification_report(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Performance:** The classification report indicates a good model of the binary classifier, Logisitic Regression model on the underlying training data, indicated by the high macro F-1 score. The precision and recall are also high for both positive & negative classes, implying the model is good at predicting both classes in the training dataset.\n",
    "\n",
    "**Validation Performance:** The classification report on the validation set shows slightly lower values than the training set, which is expected. The drop is not too drastic, implying the model does not overfit on the training data and has not memorized noise from it. The model is rather **generalized** in classifying sentiment with an adequate accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing\n",
    "\n",
    "Use the testing data to measure the accuracy and F1-score of your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The pipeline created is applied to the testing data to make it ready for obtaining model predictions from\n",
    "\n",
    "model_input_test = pipeline(df_test, function_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = model_input_test.drop(columns = ['Sentence', 'Polarity', 'processed_text'])\n",
    "y_test = model_input_test['Polarity']\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "test_prediction_prob = lr_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_predictions = [1 if p > optimal_threshold else 0 for p in test_prediction_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       287\n",
      "           1       0.83      0.67      0.74       313\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.77      0.76      0.76       600\n",
      "weighted avg       0.77      0.76      0.76       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessing Model Fit**\n",
    "\n",
    "The classification model developed is a binary classifier, which predicts positive sentiment as the positive class (1) and negative sentiment as the negative class (0). The model is **generalized** in classifying positive / negative sentiment with an adequate accuracy, and does not overfit on the training data. \n",
    "\n",
    "**Performance on Testing Data**\n",
    "\n",
    "The macro F-1 score and accuracy score are both 76%. The macro precision of the model is 77%, whereas the macro recall is 76%, implying that the model is able to correctly predict positive / negative sentiments 77 out of 100 times and 76% of all use cases are correctly captured by the model.\n",
    "\n",
    "If we look at the results of the individual positive and negative classes, we notice the positive class (which demonstrate positive sentiment) has a precision of 83% and a recall of 67%. The recall of 67% implies there are a lot of missed opportunities in predicting which statements demonstrate positive sentiment - only 67% of all positive sentiment use cases are correctly predicted for. \n",
    "\n",
    "The negative class (which demonstrates negative sentiment in this case) has a higher recall of 85%, but a slightly lower precision of 70%. This means 84% of all negative sentiment use cases are correctly predicted for, with the predictions being accurate 70 out of 100 times. \n",
    "\n",
    "**Summary**: The model is incorrectly classifying many positive sentiments as negative!\n",
    "\n",
    "The model is casting a wider net and correctly capturing more of the negative class than the positive class. The usefulness of the model would depend on the business use case it is used for - if the use case happens to be identifying negative sentiment, such as, detecting adverse drug reactions based on social media mentions, the model will capture most of the negative comments, with fewer missed opportunities. If the use case happens to be identifying positive sentiment, such as, a business owner looking to thank customers for positive online reviews, there will be a lot of missed opportunities. \n",
    "\n",
    "**Next Steps**: As explained in more detail in part 3, the model is not looking at some of the words in context and there seems to be an over-reliance on the bag-of-words. Some sentences have sarcasm, nuances, complex sentence structures and words often have double meanings. Using a pre-trained NLP API, such as, Google's BERT or OpenAI's GPT, will allow words to be understood in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases to Assess Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = (pd.DataFrame(test_predictions).merge(df_test[['Sentence', 'Polarity']], left_index = True, right_index = True)).merge(X_test,\n",
    "                                                                                                           left_index = True,\n",
    "                                                                                                           right_index = True,\n",
    "                                                                                                           how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.rename(columns = {0:'Test_Prediction'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Prediction</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>not</th>\n",
       "      <th>n't</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>phone</th>\n",
       "      <th>work</th>\n",
       "      <th>'s</th>\n",
       "      <th>...</th>\n",
       "      <th>ceas</th>\n",
       "      <th>favourit</th>\n",
       "      <th>colour</th>\n",
       "      <th>flag</th>\n",
       "      <th>subtl</th>\n",
       "      <th>special_character_count</th>\n",
       "      <th>word_count_in_review</th>\n",
       "      <th>character_count_in_review</th>\n",
       "      <th>frequent_positive_words</th>\n",
       "      <th>frequent_negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Not too screamy not to masculine but just righ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>I would have casted her in that role after rea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>The soundtrack wasn't terrible, either.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>Still, it was the SETS that got a big \"10\" on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>The last 15 minutes of movie are also not bad ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.308524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test_Prediction                                           Sentence  \\\n",
       "12                0  Not too screamy not to masculine but just righ...   \n",
       "14                0  I would have casted her in that role after rea...   \n",
       "36                0          The soundtrack wasn't terrible, either.     \n",
       "38                0  Still, it was the SETS that got a big \"10\" on ...   \n",
       "43                0  The last 15 minutes of movie are also not bad ...   \n",
       "\n",
       "    Polarity       not  n't  good  great  phone  work   's  ...  ceas  \\\n",
       "12         1  0.643795  0.0   0.0    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "14         1  0.000000  0.0   0.0    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "36         1  0.000000  0.0   0.0    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "38         1  0.000000  0.0   0.0    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "43         1  0.308524  0.0   0.0    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "\n",
       "    favourit  colour  flag  subtl  special_character_count  \\\n",
       "12       0.0     0.0   0.0    0.0                        1   \n",
       "14       0.0     0.0   0.0    0.0                        1   \n",
       "36       0.0     0.0   0.0    0.0                        1   \n",
       "38       0.0     0.0   0.0    0.0                        5   \n",
       "43       0.0     0.0   0.0    0.0                        1   \n",
       "\n",
       "    word_count_in_review  character_count_in_review  frequent_positive_words  \\\n",
       "12                     9                         50                        5   \n",
       "14                    12                         62                        5   \n",
       "36                     5                         41                        4   \n",
       "38                    14                         66                       10   \n",
       "43                    12                         56                        7   \n",
       "\n",
       "    frequent_negative_words  \n",
       "12                        5  \n",
       "14                        5  \n",
       "36                        4  \n",
       "38                       10  \n",
       "43                        7  \n",
       "\n",
       "[5 rows x 3008 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[(test_results['Test_Prediction'] == 0) & (test_results['Polarity'] == 1)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of instances where model predictions were incorrect:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Negatives**\n",
    "\n",
    "* Not too screamy not to masculine but just right.\n",
    "* I would have casted her in that role after ready the script.\n",
    "* The soundtrack wasn't terrible, either.\n",
    "* Still, it was the SETS that got a big \"10\" on my \"oy-vey\" scale.\n",
    "* The last 15 minutes of movie are also not bad as well.\n",
    "\n",
    "In some of the instances above, we notice \"double negatives\" - **\"wasn't terrible\", \"still\", \"not too screamy not to ..\", \"not bad\".** The double negative is meant to mean something positive, which wasn't properly captured by the classification model. \n",
    "\n",
    "The presence of strong negative sentiment words, such as, \"not\", \"terrible\", \"garbage\" - caused these reviews to be incorrectly classified as negative sentiment. There are features to capture the count of highly indexing positive sentiment words & negative sentiment words. \n",
    "\n",
    "There is some sarcasm and nuance in some of the comments, leading to a complex sentence construct, which wasn't properly captured by the algorithm. \n",
    "\n",
    "**The last 15 minutes of movie are also not bad as well.** - This has the words \"not bad\" to negate each other, indicating the ending of the movie was good. This sentence has 2 negative sentiment words - \"not\", \"bad\", causing this to be incorrectly classed as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Prediction</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>not</th>\n",
       "      <th>n't</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>phone</th>\n",
       "      <th>work</th>\n",
       "      <th>'s</th>\n",
       "      <th>...</th>\n",
       "      <th>ceas</th>\n",
       "      <th>favourit</th>\n",
       "      <th>colour</th>\n",
       "      <th>flag</th>\n",
       "      <th>subtl</th>\n",
       "      <th>special_character_count</th>\n",
       "      <th>word_count_in_review</th>\n",
       "      <th>character_count_in_review</th>\n",
       "      <th>frequent_positive_words</th>\n",
       "      <th>frequent_negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1</td>\n",
       "      <td>As for the killer, don't expect anything origi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm so sorry but I really can't recommend it t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1</td>\n",
       "      <td>I highly doubt that anyone could ever like thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>1</td>\n",
       "      <td>Characters are one-dimensional, even the good ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>Just whatever you do, avoid \"Groove\" as its th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test_Prediction                                           Sentence  \\\n",
       "502                1  As for the killer, don't expect anything origi...   \n",
       "504                1  I'm so sorry but I really can't recommend it t...   \n",
       "510                1  I highly doubt that anyone could ever like thi...   \n",
       "519                1  Characters are one-dimensional, even the good ...   \n",
       "553                1  Just whatever you do, avoid \"Groove\" as its th...   \n",
       "\n",
       "     Polarity  not  n't      good  great  phone  work   's  ...  ceas  \\\n",
       "502         0  0.0  0.0  0.000000    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "504         0  0.0  0.0  0.000000    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "510         0  0.0  0.0  0.000000    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "519         0  0.0  0.0  0.239244    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "553         0  0.0  0.0  0.377720    0.0    0.0   0.0  0.0  ...   0.0   \n",
       "\n",
       "     favourit  colour  flag  subtl  special_character_count  \\\n",
       "502       0.0     0.0   0.0    0.0                        1   \n",
       "504       0.0     0.0   0.0    0.0                        2   \n",
       "510       0.0     0.0   0.0    0.0                        1   \n",
       "519       0.0     0.0   0.0    0.0                        1   \n",
       "553       0.0     0.0   0.0    0.0                        4   \n",
       "\n",
       "     word_count_in_review  character_count_in_review  frequent_positive_words  \\\n",
       "502                    12                         81                        8   \n",
       "504                    11                         57                        7   \n",
       "510                    10                         56                        7   \n",
       "519                    12                         81                        8   \n",
       "553                    18                        101                        9   \n",
       "\n",
       "     frequent_negative_words  \n",
       "502                        8  \n",
       "504                        7  \n",
       "510                        7  \n",
       "519                        8  \n",
       "553                        9  \n",
       "\n",
       "[5 rows x 3008 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[(test_results['Test_Prediction'] == 1) & (test_results['Polarity'] == 0)].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positives**\n",
    "\n",
    "* As for the killer, don't expect anything original or even remotely frightening.\n",
    "* I'm so sorry but I really can't recommend it to anyone.\t\n",
    "* I highly doubt that anyone could ever like this trash.\n",
    "* Characters are one-dimensional, even the good guys and especially the bad guys.\n",
    "* Just whatever you do, avoid \"Groove\" as its the antithesis of all that is good about Human Traffic.\n",
    "\n",
    "The sentences which are incorrectly classified as positive sentiment contain strong positive sentiment words, such as, \"original\", \"good\", \"like\", etc. \n",
    "\n",
    "Some sentences have apologies or sarcasm, which are complex sentence structures, which are not properly captured by the model. Sentences have nuances, such as, \"or even remotely\", which seem to be interpreted by the model quite literally and not in context, leading to an incorrect sentiment prediction. There seems to be an over-reliance on the bag of words and the frequency of words (tf-idf), causing some words / phrases to be taken quite literally and not in context. \n",
    "\n",
    "**\"I'm so sorry but I really can't recommend it to anyone\"** - the word \"sorry\" appears to be a negative sentiment word, but in this case, the sorry is used to refer to an apology. It must also be noted that certain words can have double meanings and not reading the sentence in context, can cause the model to incorrectly classify its sentiment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
